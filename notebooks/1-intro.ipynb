{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout\n",
    "\n",
    "+ opening\n",
    "    + contents\n",
    "    + files used\n",
    "    + packages used\n",
    "\n",
    "+ Scraping\n",
    "    + Images\n",
    "        + OCR\n",
    "    + raw text\n",
    "    + html\n",
    "    + PDFs\n",
    "    + word doc etc.\n",
    "+ spidering\n",
    "    + wikipedia\n",
    "    + APIs\n",
    "        + REST\n",
    "        + tumblr\n",
    "+ reading files\n",
    "    + encodings\n",
    "    + unicode\n",
    "+ filtering\n",
    "+ data structures\n",
    "    + pandas\n",
    "\n",
    "\n",
    "# Week 1 - Intro\n",
    "\n",
    "Intro stuff ...\n",
    "\n",
    "For this notebook we will be using the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #http requests\n",
    "import bs4 #called 'BeautifulSoup', a html parser\n",
    "import re #for regexs\n",
    "import pandas #DataFrames\n",
    "import urllib.parse #For joining urls\n",
    "import io\n",
    "import PyPDF2 #For reading pdfs\n",
    "import docx #MS doc files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be working on the following files/urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "example_text_file = 'sometextfile.txt'\n",
    "information_extraction_pdf = 'https://web.stanford.edu/~jurafsky/slp3/20.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "Before we can start analyzing content we need to obtain it. Sometimes it will be provided to us before hand, but often we will need to download it. As a starting example we will attempt to download the wikipedia page on content analysis. The page is located at [https://en.wikipedia.org/wiki/Content_analysis](https://en.wikipedia.org/wiki/Content_analysis) so lets start with that.\n",
    "\n",
    "We can do this by making an HTTP GET request to that url, a GET request is simply a request to the server to provide the contents given by some url. The other request we will be using in this class is called a POST request and requests the server to take some content we provide. While the Python standard library does have the ability do make GET requests we will be using the [_requests_](http://docs.python-requests.org/en/master/) package as it is _'the only Non-GMO HTTP library for Python'_, also it provides a nicer interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "requests.get('https://en.wikipedia.org/wiki/Content_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Response [200]'` means the server responded with what we asked for. If you get another number (e.g. 404) it likely means there was some kind of error, these codes are called HTTP response codes and a list of them can be found [here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). The response object contains all the data the server sent including the website's contents and the HTTP header. We are interested in the contents which we can access with the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Content analysis - Wikipedia</title>\n",
      "<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n",
      "<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Content_analysis\",\"wgTitle\":\"Content analysis\",\"wgCurRevisionId\":735443188,\"wgRevisionId\":735443188,\"wgArticleId\":473317,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles needing cleanup from April 2008\",\"All articles needing cleanup\",\"Cleanup tagged articles without a reason field from April 2008\",\"Wikipedia pages needing cleanup from April 2008\",\"Articles needing expert attention with no reason or talk parameter\",\"Articles needing expert attention from April 2008\",\"All artic\n"
     ]
    }
   ],
   "source": [
    "wikiContentRequest = requests.get('https://en.wikipedia.org/wiki/Content_analysis')\n",
    "print(wikiContentRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we were looking for, because it is the start of the HTML that makes up the website. This is HTML and is meant to be read by computers. Luckily we have a computer to parse it for us. To do the parsing we will use [_Beautiful Soup_](https://www.crummy.com/software/BeautifulSoup/) which is a better parser than the one in the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis - Wikipedia\n",
      "document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );\n",
      "(window.RLQ=window.RLQ||[]).push(functio\n"
     ]
    }
   ],
   "source": [
    "wikiContentSoup = bs4.BeautifulSoup(wikiContentRequest.text, 'html.parser')\n",
    "print(wikiContentSoup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better but there's a bunch of random whitespace and we have way more than just the text of the article. This is because what we requested is the whole webpage, not just the text for the article.\n",
    "\n",
    "We need to extract only the text we care about, in order to do this we will need to inspect the html. One way to do this is to simply go to the website with a browser and use its inspection or view source tool, but if there is javascript or other dynamic loading occurring on the page it is very likely that what Python receives is not what you will see. So we will need to view what Python receives. To do this we can save the html `requests` obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "\n",
    "with open(content_analysis_save, mode='w', encoding='utf-8') as f:\n",
    "    f.write(wikiContentRequest.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets open the file (`wikipedia_content_analysis.html`) we just created with a web browser. It should look sort of like the original but missing all the images and formatting.\n",
    "\n",
    "As there is very little standardization on structuring webpages figuring out how best to extract what you want is an art. Looking at this page it looks like all the main textual content is within `<p>`(paragraph) tags inside the `<body>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content analysis is \"a wide and heterogeneous set of manual or computer-assisted techniques for contextualized interpretations of documents produced by communication processes in the strict sense of that phrase (any kind of text, written, iconic, multimedia, etc.) or signification processes (traces and artifacts), having as ultimate goal the production of valid and trustworthy inferences.\"\n",
      "Content analysis has come to be a sort of 'umbrella term' referring to an almost boundless set of quite diverse research approaches and techniques. Broadly, it can refer to methods for studying and/or retrieving meaningful information from documents.[1] In a more focused way, content analysis refers to a family of techniques for studying the \"mute evidence\" of texts and artifacts.[2] There are 5 types of texts in content analysis:\n",
      "Content analysis can also be described as studying traces, which are documents from past times, and artifacts, which are non-linguistic documents. Texts are understood to be produced by communication processes in a broad sense of that phrase - often gaining mean through abduction.[1][3]\n"
     ]
    }
   ],
   "source": [
    "contentPTags = wikiContentSoup.body.findAll('p')\n",
    "for pTag in contentPTags[:3]:\n",
    "    print(pTag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the text from the page, split up by paragraph. If we wanted to get the section headers or references as well it would require a bit more work, but is doable.\n",
    "\n",
    "There is one more thing we might want to do before sending this text to be processed, remove the references indicators (`[2]`, `[3]` , etc). To do this we can use a short regular expression (regex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       paragraph-text\n",
      "0   Content analysis is \"a wide and heterogeneous ...\n",
      "1   Content analysis has come to be a sort of 'umb...\n",
      "2   Content analysis can also be described as stud...\n",
      "3   Despite the wide variety of options, generally...\n",
      "4   Over the years, content analysis has been appl...\n",
      "5   In recent times, particularly with the advent ...\n",
      "6   Quantitative content analysis has enjoyed a re...\n",
      "7                                                    \n",
      "8                                                    \n",
      "9   The method of content analysis enables the res...\n",
      "10  Since the 1980s, content analysis has become a...\n",
      "11  The creation of coding frames is intrinsically...\n",
      "12  Mimetic Convergence thus aims to show the proc...\n",
      "13  Every content analysis should depart from a hy...\n",
      "14  As an evaluation approach, content analysis is...\n",
      "15  Qualitative content analysis is “a systematic,...\n",
      "16  Holsti groups fifteen uses of content analysis...\n",
      "17  He also places these uses into the context of ...\n",
      "18  The following table shows fifteen uses of cont...\n",
      "19  According to Dr. Klaus Krippendorff, six quest...\n",
      "20  The assumption is that words and phrases menti...\n",
      "21  Qualitatively, content analysis can involve an...\n",
      "22  Normally, content analysis can only be applied...\n",
      "23  A further step in analysis is the distinction ...\n",
      "24  Dermot McKeone highlighted the difference betw...\n",
      "25  As the uncritical use of text is today widely ...\n",
      "26  Neuendorf suggests that when human coders are ...\n"
     ]
    }
   ],
   "source": [
    "contentParagraphs = []\n",
    "for pTag in contentPTags:\n",
    "    #strings starting with r are raw so their \\'s are not modifier characters\n",
    "    #If we didn't start with r the string would be: '\\\\[\\\\d+\\\\]'\n",
    "    contentParagraphs.append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "\n",
    "#convert to a DataFrame\n",
    "contentParagraphsDF = pandas.DataFrame({'paragraph-text' : contentParagraphs})\n",
    "print(contentParagraphsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `DataFrame` of all the relevant text from the page ready to be processed\n",
    "\n",
    "If you are not familiar with regex, it is a way of specifying searches of text. A regex engine takes in the search pattern, in the above case `'\\[\\d+\\]'` and some string, the paragraph texts. Then it reads the input string one character at a time checking if it matches the search. For example the regex `'\\d'` matches number characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(36, 37), match='2'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findNumber = r'\\d'\n",
    "regexResults = re.search(findNumber, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "regexResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python the regex package (`re`) usually returns `Match` objects (you can have multiple pattern hits in a a single `Match`), to get the string that matched our pattern we can use the `.group()` method, and as we want the first one will will ask for the 0'th group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us the first number, if we wanted the whole block of numbers we can add a wildcard `'+'` which requests 1 or more instances of the proceeding character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134567890\n"
     ]
    }
   ],
   "source": [
    "findNumbers = r'\\d+'\n",
    "regexResults = re.search(findNumbers, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the whole block of numbers, there are a huge number of special characters in regex, for the full description of Python's implementation look at the [re docs](https://docs.python.org/3/library/re.html) there is also a short [tutorial](https://docs.python.org/3/howto/regex.html#regex-howto).\n",
    "\n",
    "# Spidering\n",
    "\n",
    "What if we want to to get a bunch of different pages from wikipedia. We would need to get the url of each of the pages we want, usually we will want pages that are linked to by other pages, so we will need to parse pages and find the links. Right now we will be getting all the links in the body of the content analysis page.\n",
    "\n",
    "To do this we will need to find all the `<a>` (anchor) tags with `href`s (hyperlink references) inside of `<p>` tags. `href` can have many [different](http://stackoverflow.com/questions/4855168/what-is-href-and-why-is-it-used) [forms](https://en.wikipedia.org/wiki/Hyperlink#Hyperlinks_in_HTML) so dealing with them can be tricky generally though you be extracting from it absolute or relative links. An absolute link is one you can follow with out any modification, while a relative link has a base url that you are then appending. Wikipedia uses relative urls for its internal links so below is an example of dealing with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://en.wikipedia.org/wiki/Text_(literary_theory)', 1, 'texts'), ('https://en.wikipedia.org/wiki/Trace_evidence', 2, 'traces'), ('https://en.wikipedia.org/wiki/Abductive_reasoning', 2, 'abduction'), ('https://en.wikipedia.org/wiki/Hermeneutics', 4, 'Hermeneutics'), ('https://en.wikipedia.org/wiki/Philology', 4, 'Philology'), ('https://en.wikipedia.org/wiki/Authentication', 4, 'authenticity'), ('https://en.wikipedia.org/wiki/Mass_communication', 5, 'mass communication'), ('https://en.wikipedia.org/wiki/Harold_Lasswell', 5, 'Harold Lasswell'), ('https://en.wikipedia.org/wiki/Bernard_Berelson', 5, 'Bernard Berelson'), ('https://en.wikipedia.org/wiki/Big_data', 6, 'big data')]\n"
     ]
    }
   ],
   "source": [
    "#wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "\n",
    "otherPAgeURLS = []\n",
    "#We also want to know where the links come from so we also will get:\n",
    "#the paragraph number\n",
    "#the word the link is in\n",
    "for paragraphNum, pTag in enumerate(contentPTags):\n",
    "    #we only want hrefs that link to wiki pages\n",
    "    tagLinks = pTag.findAll('a', href=re.compile('/wiki/'), class_=False)\n",
    "    for aTag in tagLinks:\n",
    "        #We need to extract the url from the <a> tag\n",
    "        relurl = aTag.get('href')\n",
    "        linkText = aTag.text\n",
    "        #wikipedia_base_url is the base we can use the urllib joining function to merge them\n",
    "        #Giving a nice structured tupe like this means we can use tuple expansion later\n",
    "        otherPAgeURLS.append((\n",
    "            urllib.parse.urljoin(wikipedia_base_url, relurl),\n",
    "            paragraphNum,\n",
    "            linkText,\n",
    "        ))\n",
    "print(otherPAgeURLS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be adding these new texts to our DataFrame `contentParagraphsDF` so we will need to add 2 more columns to keep track of paragraph numbers and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>paragraph-number</th>\n",
       "      <th>source-paragraph-number</th>\n",
       "      <th>source-paragraph-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Content analysis is \"a wide and heterogeneous ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Content analysis has come to be a sort of 'umb...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despite the wide variety of options, generally...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The method of content analysis enables the res...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Since the 1980s, content analysis has become a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The creation of coding frames is intrinsically...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mimetic Convergence thus aims to show the proc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Every content analysis should depart from a hy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>As an evaluation approach, content analysis is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qualitative content analysis is “a systematic,...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>According to Dr. Klaus Krippendorff, six quest...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The assumption is that words and phrases menti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Qualitatively, content analysis can involve an...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Normally, content analysis can only be applied...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dermot McKeone highlighted the difference betw...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>As the uncritical use of text is today widely ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Neuendorf suggests that when human coders are ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paragraph-text  \\\n",
       "0   Content analysis is \"a wide and heterogeneous ...   \n",
       "1   Content analysis has come to be a sort of 'umb...   \n",
       "2   Content analysis can also be described as stud...   \n",
       "3   Despite the wide variety of options, generally...   \n",
       "4   Over the years, content analysis has been appl...   \n",
       "5   In recent times, particularly with the advent ...   \n",
       "6   Quantitative content analysis has enjoyed a re...   \n",
       "7                                                       \n",
       "8                                                       \n",
       "9   The method of content analysis enables the res...   \n",
       "10  Since the 1980s, content analysis has become a...   \n",
       "11  The creation of coding frames is intrinsically...   \n",
       "12  Mimetic Convergence thus aims to show the proc...   \n",
       "13  Every content analysis should depart from a hy...   \n",
       "14  As an evaluation approach, content analysis is...   \n",
       "15  Qualitative content analysis is “a systematic,...   \n",
       "16  Holsti groups fifteen uses of content analysis...   \n",
       "17  He also places these uses into the context of ...   \n",
       "18  The following table shows fifteen uses of cont...   \n",
       "19  According to Dr. Klaus Krippendorff, six quest...   \n",
       "20  The assumption is that words and phrases menti...   \n",
       "21  Qualitatively, content analysis can involve an...   \n",
       "22  Normally, content analysis can only be applied...   \n",
       "23  A further step in analysis is the distinction ...   \n",
       "24  Dermot McKeone highlighted the difference betw...   \n",
       "25  As the uncritical use of text is today widely ...   \n",
       "26  Neuendorf suggests that when human coders are ...   \n",
       "\n",
       "                                            source  paragraph-number  \\\n",
       "0   https://en.wikipedia.org/wiki/Content_analysis                 0   \n",
       "1   https://en.wikipedia.org/wiki/Content_analysis                 1   \n",
       "2   https://en.wikipedia.org/wiki/Content_analysis                 2   \n",
       "3   https://en.wikipedia.org/wiki/Content_analysis                 3   \n",
       "4   https://en.wikipedia.org/wiki/Content_analysis                 4   \n",
       "5   https://en.wikipedia.org/wiki/Content_analysis                 5   \n",
       "6   https://en.wikipedia.org/wiki/Content_analysis                 6   \n",
       "7   https://en.wikipedia.org/wiki/Content_analysis                 7   \n",
       "8   https://en.wikipedia.org/wiki/Content_analysis                 8   \n",
       "9   https://en.wikipedia.org/wiki/Content_analysis                 9   \n",
       "10  https://en.wikipedia.org/wiki/Content_analysis                10   \n",
       "11  https://en.wikipedia.org/wiki/Content_analysis                11   \n",
       "12  https://en.wikipedia.org/wiki/Content_analysis                12   \n",
       "13  https://en.wikipedia.org/wiki/Content_analysis                13   \n",
       "14  https://en.wikipedia.org/wiki/Content_analysis                14   \n",
       "15  https://en.wikipedia.org/wiki/Content_analysis                15   \n",
       "16  https://en.wikipedia.org/wiki/Content_analysis                16   \n",
       "17  https://en.wikipedia.org/wiki/Content_analysis                17   \n",
       "18  https://en.wikipedia.org/wiki/Content_analysis                18   \n",
       "19  https://en.wikipedia.org/wiki/Content_analysis                19   \n",
       "20  https://en.wikipedia.org/wiki/Content_analysis                20   \n",
       "21  https://en.wikipedia.org/wiki/Content_analysis                21   \n",
       "22  https://en.wikipedia.org/wiki/Content_analysis                22   \n",
       "23  https://en.wikipedia.org/wiki/Content_analysis                23   \n",
       "24  https://en.wikipedia.org/wiki/Content_analysis                24   \n",
       "25  https://en.wikipedia.org/wiki/Content_analysis                25   \n",
       "26  https://en.wikipedia.org/wiki/Content_analysis                26   \n",
       "\n",
       "   source-paragraph-number source-paragraph-text  \n",
       "0                     None                  None  \n",
       "1                     None                  None  \n",
       "2                     None                  None  \n",
       "3                     None                  None  \n",
       "4                     None                  None  \n",
       "5                     None                  None  \n",
       "6                     None                  None  \n",
       "7                     None                  None  \n",
       "8                     None                  None  \n",
       "9                     None                  None  \n",
       "10                    None                  None  \n",
       "11                    None                  None  \n",
       "12                    None                  None  \n",
       "13                    None                  None  \n",
       "14                    None                  None  \n",
       "15                    None                  None  \n",
       "16                    None                  None  \n",
       "17                    None                  None  \n",
       "18                    None                  None  \n",
       "19                    None                  None  \n",
       "20                    None                  None  \n",
       "21                    None                  None  \n",
       "22                    None                  None  \n",
       "23                    None                  None  \n",
       "24                    None                  None  \n",
       "25                    None                  None  \n",
       "26                    None                  None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentParagraphsDF['source'] = [wikipedia_content_analysis] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['paragraph-number'] = range(len(contentParagraphsDF['paragraph-text']))\n",
    "contentParagraphsDF['source-paragraph-number'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['source-paragraph-text'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a function to parse each linked page and add its text to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getTextFromWikiPage(targetURL, sourceParNum, sourceText):\n",
    "    #Make a dict to store data before adding it to the DataFrame\n",
    "    parsDict = {'source' : [], 'paragraph-number' : [], 'paragraph-text' : [], 'source-paragraph-number' : [],  'source-paragraph-text' : []}\n",
    "    #Now we get the page\n",
    "    r = requests.get(targetURL)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #enumerating gives use the paragraph number\n",
    "    for parNum, pTag in enumerate(soup.body.findAll('p')):\n",
    "        #same regex as before\n",
    "        parsDict['paragraph-text'].append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "        parsDict['paragraph-number'].append(parNum)\n",
    "        parsDict['source'].append(targetURL)\n",
    "        parsDict['source-paragraph-number'].append(sourceParNum)\n",
    "        parsDict['source-paragraph-text'].append(sourceText)\n",
    "    return pandas.DataFrame(parsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it on our list of link tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-number</th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>source-paragraph-number</th>\n",
       "      <th>source-paragraph-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Content analysis is \"a wide and heterogeneous ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Content analysis has come to be a sort of 'umb...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Despite the wide variety of options, generally...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>The method of content analysis enables the res...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Since the 1980s, content analysis has become a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>The creation of coding frames is intrinsically...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Mimetic Convergence thus aims to show the proc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Every content analysis should depart from a hy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>As an evaluation approach, content analysis is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Qualitative content analysis is “a systematic,...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>According to Dr. Klaus Krippendorff, six quest...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>The assumption is that words and phrases menti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Qualitatively, content analysis can involve an...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Normally, content analysis can only be applied...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Dermot McKeone highlighted the difference betw...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>As the uncritical use of text is today widely ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Neuendorf suggests that when human coders are ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>In literary theory, a text is any object that ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>Within the field of literary criticism, \"text\"...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>Since the history of writing predates the conc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>53</td>\n",
       "      <td>The hypothesis is framed, but not asserted, in...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>54</td>\n",
       "      <td>Note that the hypothesis (\"A\") could be of a r...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>55</td>\n",
       "      <td>Peirce did not remain quite convinced about an...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>56</td>\n",
       "      <td>In 1901 Peirce wrote, \"There would be no logic...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>57</td>\n",
       "      <td>\"Consider what effects, that might conceivably...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>58</td>\n",
       "      <td>It is a method for fruitful clarification of c...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>59</td>\n",
       "      <td>Peirce came over the years to divide (philosop...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>60</td>\n",
       "      <td>Peirce had, from the start, seen the modes of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>61</td>\n",
       "      <td>As early as 1866, Peirce held that:</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>62</td>\n",
       "      <td>1. Hypothesis (abductive inference) is inferen...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>63</td>\n",
       "      <td>In 1902, Peirce wrote that, in abduction: \"It ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>64</td>\n",
       "      <td>At the critical level Peirce examined the form...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>65</td>\n",
       "      <td>The phrase \"inference to the best explanation\"...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>66</td>\n",
       "      <td>At the methodeutical level Peirce held that a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>67</td>\n",
       "      <td>Norwood Russell Hanson, a philosopher of scien...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>68</td>\n",
       "      <td>Further development of the concept can be foun...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>69</td>\n",
       "      <td>Applications in artificial intelligence includ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>70</td>\n",
       "      <td>In medicine, abduction can be seen as a compon...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>71</td>\n",
       "      <td>Abduction can also be used to model automated ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>72</td>\n",
       "      <td>In intelligence analysis, analysis of competin...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>73</td>\n",
       "      <td>Belief revision, the process of adapting belie...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>74</td>\n",
       "      <td>In the philosophy of science, abduction has be...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>75</td>\n",
       "      <td>In historical linguistics, abduction during la...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>76</td>\n",
       "      <td>In anthropology, Alfred Gell in his influentia...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>77</td>\n",
       "      <td>Consequently, to discover is simply to expedit...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>78</td>\n",
       "      <td>It allows any flight of imagination, provided ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>79</td>\n",
       "      <td>Methodeutic has a special interest in Abductio...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>80</td>\n",
       "      <td>.... What is good abduction? What should an ex...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>81</td>\n",
       "      <td>The mind seeks to bring the facts, as modified...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>82</td>\n",
       "      <td>Thus, twenty skillful hypotheses will ascertai...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abductive_reasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>abduction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paragraph-number                                     paragraph-text  \\\n",
       "0                   0  Content analysis is \"a wide and heterogeneous ...   \n",
       "1                   1  Content analysis has come to be a sort of 'umb...   \n",
       "2                   2  Content analysis can also be described as stud...   \n",
       "3                   3  Despite the wide variety of options, generally...   \n",
       "4                   4  Over the years, content analysis has been appl...   \n",
       "5                   5  In recent times, particularly with the advent ...   \n",
       "6                   6  Quantitative content analysis has enjoyed a re...   \n",
       "7                   7                                                      \n",
       "8                   8                                                      \n",
       "9                   9  The method of content analysis enables the res...   \n",
       "10                 10  Since the 1980s, content analysis has become a...   \n",
       "11                 11  The creation of coding frames is intrinsically...   \n",
       "12                 12  Mimetic Convergence thus aims to show the proc...   \n",
       "13                 13  Every content analysis should depart from a hy...   \n",
       "14                 14  As an evaluation approach, content analysis is...   \n",
       "15                 15  Qualitative content analysis is “a systematic,...   \n",
       "16                 16  Holsti groups fifteen uses of content analysis...   \n",
       "17                 17  He also places these uses into the context of ...   \n",
       "18                 18  The following table shows fifteen uses of cont...   \n",
       "19                 19  According to Dr. Klaus Krippendorff, six quest...   \n",
       "20                 20  The assumption is that words and phrases menti...   \n",
       "21                 21  Qualitatively, content analysis can involve an...   \n",
       "22                 22  Normally, content analysis can only be applied...   \n",
       "23                 23  A further step in analysis is the distinction ...   \n",
       "24                 24  Dermot McKeone highlighted the difference betw...   \n",
       "25                 25  As the uncritical use of text is today widely ...   \n",
       "26                 26  Neuendorf suggests that when human coders are ...   \n",
       "27                  0  In literary theory, a text is any object that ...   \n",
       "28                  1  Within the field of literary criticism, \"text\"...   \n",
       "29                  2  Since the history of writing predates the conc...   \n",
       "..                ...                                                ...   \n",
       "99                 53  The hypothesis is framed, but not asserted, in...   \n",
       "100                54  Note that the hypothesis (\"A\") could be of a r...   \n",
       "101                55  Peirce did not remain quite convinced about an...   \n",
       "102                56  In 1901 Peirce wrote, \"There would be no logic...   \n",
       "103                57  \"Consider what effects, that might conceivably...   \n",
       "104                58  It is a method for fruitful clarification of c...   \n",
       "105                59  Peirce came over the years to divide (philosop...   \n",
       "106                60  Peirce had, from the start, seen the modes of ...   \n",
       "107                61                As early as 1866, Peirce held that:   \n",
       "108                62  1. Hypothesis (abductive inference) is inferen...   \n",
       "109                63  In 1902, Peirce wrote that, in abduction: \"It ...   \n",
       "110                64  At the critical level Peirce examined the form...   \n",
       "111                65  The phrase \"inference to the best explanation\"...   \n",
       "112                66  At the methodeutical level Peirce held that a ...   \n",
       "113                67  Norwood Russell Hanson, a philosopher of scien...   \n",
       "114                68  Further development of the concept can be foun...   \n",
       "115                69  Applications in artificial intelligence includ...   \n",
       "116                70  In medicine, abduction can be seen as a compon...   \n",
       "117                71  Abduction can also be used to model automated ...   \n",
       "118                72  In intelligence analysis, analysis of competin...   \n",
       "119                73  Belief revision, the process of adapting belie...   \n",
       "120                74  In the philosophy of science, abduction has be...   \n",
       "121                75  In historical linguistics, abduction during la...   \n",
       "122                76  In anthropology, Alfred Gell in his influentia...   \n",
       "123                77  Consequently, to discover is simply to expedit...   \n",
       "124                78  It allows any flight of imagination, provided ...   \n",
       "125                79  Methodeutic has a special interest in Abductio...   \n",
       "126                80  .... What is good abduction? What should an ex...   \n",
       "127                81  The mind seeks to bring the facts, as modified...   \n",
       "128                82  Thus, twenty skillful hypotheses will ascertai...   \n",
       "\n",
       "                                                source  \\\n",
       "0       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "1       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "2       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "3       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "4       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "5       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "6       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "7       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "8       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "9       https://en.wikipedia.org/wiki/Content_analysis   \n",
       "10      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "11      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "12      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "13      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "14      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "15      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "16      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "17      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "18      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "19      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "20      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "21      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "22      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "23      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "24      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "25      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "26      https://en.wikipedia.org/wiki/Content_analysis   \n",
       "27   https://en.wikipedia.org/wiki/Text_(literary_t...   \n",
       "28   https://en.wikipedia.org/wiki/Text_(literary_t...   \n",
       "29   https://en.wikipedia.org/wiki/Text_(literary_t...   \n",
       "..                                                 ...   \n",
       "99   https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "100  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "101  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "102  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "103  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "104  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "105  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "106  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "107  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "108  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "109  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "110  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "111  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "112  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "113  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "114  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "115  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "116  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "117  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "118  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "119  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "120  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "121  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "122  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "123  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "124  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "125  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "126  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "127  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "128  https://en.wikipedia.org/wiki/Abductive_reasoning   \n",
       "\n",
       "     source-paragraph-number source-paragraph-text  \n",
       "0                        NaN                   NaN  \n",
       "1                        NaN                   NaN  \n",
       "2                        NaN                   NaN  \n",
       "3                        NaN                   NaN  \n",
       "4                        NaN                   NaN  \n",
       "5                        NaN                   NaN  \n",
       "6                        NaN                   NaN  \n",
       "7                        NaN                   NaN  \n",
       "8                        NaN                   NaN  \n",
       "9                        NaN                   NaN  \n",
       "10                       NaN                   NaN  \n",
       "11                       NaN                   NaN  \n",
       "12                       NaN                   NaN  \n",
       "13                       NaN                   NaN  \n",
       "14                       NaN                   NaN  \n",
       "15                       NaN                   NaN  \n",
       "16                       NaN                   NaN  \n",
       "17                       NaN                   NaN  \n",
       "18                       NaN                   NaN  \n",
       "19                       NaN                   NaN  \n",
       "20                       NaN                   NaN  \n",
       "21                       NaN                   NaN  \n",
       "22                       NaN                   NaN  \n",
       "23                       NaN                   NaN  \n",
       "24                       NaN                   NaN  \n",
       "25                       NaN                   NaN  \n",
       "26                       NaN                   NaN  \n",
       "27                         1                 texts  \n",
       "28                         1                 texts  \n",
       "29                         1                 texts  \n",
       "..                       ...                   ...  \n",
       "99                         2             abduction  \n",
       "100                        2             abduction  \n",
       "101                        2             abduction  \n",
       "102                        2             abduction  \n",
       "103                        2             abduction  \n",
       "104                        2             abduction  \n",
       "105                        2             abduction  \n",
       "106                        2             abduction  \n",
       "107                        2             abduction  \n",
       "108                        2             abduction  \n",
       "109                        2             abduction  \n",
       "110                        2             abduction  \n",
       "111                        2             abduction  \n",
       "112                        2             abduction  \n",
       "113                        2             abduction  \n",
       "114                        2             abduction  \n",
       "115                        2             abduction  \n",
       "116                        2             abduction  \n",
       "117                        2             abduction  \n",
       "118                        2             abduction  \n",
       "119                        2             abduction  \n",
       "120                        2             abduction  \n",
       "121                        2             abduction  \n",
       "122                        2             abduction  \n",
       "123                        2             abduction  \n",
       "124                        2             abduction  \n",
       "125                        2             abduction  \n",
       "126                        2             abduction  \n",
       "127                        2             abduction  \n",
       "128                        2             abduction  \n",
       "\n",
       "[129 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for urlTuple in otherPAgeURLS[:3]:\n",
    "    #ignore_index means the indices will not be reset after each append\n",
    "    contentParagraphsDF = contentParagraphsDF.append(getTextFromWikiPage(*urlTuple),ignore_index=True)\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tumblr API\n",
    "\n",
    "[https://www.tumblr.com/docs/en/api/v2](https://www.tumblr.com/docs/en/api/v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#r = requests.get('https://api.tumblr.com/v2/blog/scipsy.tumblr.com/info')\n",
    "#requests.get('https://api.tumblr.com/v2/blog/david.tumblr.com/avatar/512')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files\n",
    "\n",
    "What if the text we want isn't on a webpage? There are a many other sources of text available.\n",
    "\n",
    "## Raw text\n",
    "\n",
    "The most basic form of storing text is as a _raw text_ document. Source code (`.py`, `.r`, etc) is usually raw text as are text files (`.txt`) and many other things. Opening an unknown file with a text editor is often a great way of learning what the file is.\n",
    "\n",
    "We can create a text file with the `open()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_text_file = 'sometextfile.txt'\n",
    "#stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols \\u2421 \\u241B \\u20A0 \\u20A1 \\u20A2 \\u20A3 \\u0D60\\n'\n",
    "stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\\n'\n",
    "\n",
    "with open(example_text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(stringToWrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice though the `encoding='utf-8'` argument, the encoding specifies how we map the bits from the file to the glyphs (and whitespace characters like tab (`'\\t'`) or newline (`'\\n'`)) on the screen. When dealing only with latin letters, arabic numerals and the other symbols on America keyboards you usually do not have to worry about encodings as the ones used today are backwards compatible with [ASCII](https://en.wikipedia.org/wiki/ASCII) which gives the binary representation of 128 characters.\n",
    "\n",
    "Some people though use other characters. To solve this there is [Unicode](https://en.wikipedia.org/wiki/Unicode) which gives numbers to symbols, e.g. 041 is `'A'` and 03A3 is `'Σ'` (number starting with 0 indicates they are hexadecimal), often non-ASCII characters are called Unicode characters. Unfortunately there are many ways used to map combinations of bits to Unicode symbols. The ones you are likely to encounter are called by Python _utf-8_, _utf-16_ and _latin-1_. _utf-8_ is the standard for Linux and Mac OS while both _utf-16_ and _latin-1_ are used by windows. If you use the wrong encoding characters can appear wrong, sometimes change in number or Python could raise an exception. Lets see what happens when we open the file we just created with different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is with the correct encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\n",
      "\n",
      "This is with the wrong encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols â¡ â â  â¡ â¢ â£ àµ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(example_text_file, encoding='utf-8') as f:\n",
    "    print(\"This is with the correct encoding:\")\n",
    "    print(f.read())\n",
    "\n",
    "with open(example_text_file, encoding='latin-1') as f:\n",
    "    print(\"This is with the wrong encoding:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with _latin-1_ the unicode characters are mixed up and there are too many of them. You need to keep in mind encoding when obtaining text files, as determining the encoding can sometime be a lot of work.\n",
    "\n",
    "## PDF\n",
    "\n",
    "Another common way text will be stored is in a PDF file. First we will download a pdf in Python. To do that lets grab a chapter from\n",
    "_Speech and Language Processing_, chapter 20 is on Information Extraction which seems apt. It is stored as a pdf at [https://web.stanford.edu/~jurafsky/slp3/20.pdf](https://web.stanford.edu/~jurafsky/slp3/20.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.5\n",
      "%����\n",
      "97 0 obj\n",
      "<<\n",
      "/Length 2982      \n",
      "/Filter /FlateDecode\n",
      ">>\n",
      "stream\n",
      "xڝYY��\u0011~�_��T,U�\u0018\u0012����f<{����Rv\u001e",
      "(\n",
      "���������\u0000Ei���_�F�\u00014�n�s\u000e�缹����_^����Y������\"7\u0004����d��s~^}:i]\u001c",
      "כHE���\t�c�\u001c",
      "���e��k\u000b",
      "��esp�\u001bߋ���yS�Jf\u0018�|�?>���\u0006�׺\u0017�+��y7����==w��8�����\u0013\u0004�M<�x�\n",
      "����`?���Q�\u001f*gs����#C8����8\n",
      "�G�\u001b�(�s#�9�t\u0007�\n",
      "i)s|�͢H\u0011������$�����v��Շ���W[�\u0016��f��{\u001e",
      "�M��M�(�M=gã�\n",
      "�蒟��\b>�\u000e��ڊQn1\u001c",
      "�,�V��י\u0002^wU��Z�\u0019��u���\u000b",
      "\u0019\u0016�b����`��l!�!�+��)��\u000b",
      "\u001a��$����`x+�]XV\u0012�p!\u0013Y>��\u000e�J�\u001f�)\u0014���7��Xʰ��%��\be��M\u0010�ǭ������\u0012�\u0018��\u0007���s;\n",
      "*��\\��o^=���\u001c",
      "���\u0010\u001ad�8��P��P����\u0018@p��^(�&N�[L�d)�H�\u0012����a����\u001awf��\u0011!\u001d",
      "�\b�톁�$(dI\u0011f��h�4���\u0015;J,O��\u0005��4�pI\u001c",
      "�\f",
      "�/\u001bn����\u000b",
      "0�f���\u001d",
      "�\u001d",
      "\u0012\u000b",
      "�:\u0010�!\u0018���\"�L��t�kC��BT�'0[}�)\u001c",
      "|-a�\u0017\u001b��4(\u0011��f��\u0002��ï��w��:�V�-#���\u0017����\tbZ2�\u0004��|ێ� �(\u0001O�e�\u0001��P�.ς!�\n"
     ]
    }
   ],
   "source": [
    "#information_extraction_pdf = 'https://web.stanford.edu/~jurafsky/slp3/20.pdf'\n",
    "\n",
    "infoExtractionRequest = requests.get(information_extraction_pdf, stream=True)\n",
    "print(infoExtractionRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It says `'pdf'`, so thats a good sign, the rest though looks like we are having issues with an encoding. The random characters are not though caused by our encoding being wrong they are cause by there not being an encoding for those parts at all. PDFs are nominally binary files, meaning there are sections of binary that are specific to pdf and nothing else so you need something that knows about pdf to read them. To do that we will be using [`PyPDF2`](https://github.com/mstamy2/PyPDF2) which is a PDF processing library for Python 3.\n",
    "\n",
    "**NOTE** maybe use `PyPDF2` or `slate`\n",
    "\n",
    "But first we need to take the response object and convert it into a 'file like' object so that PyPDF2 can read it. To do this we will use `io`'s `BytesIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoExtractionBytes = io.BytesIO(infoExtractionRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can give it to PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "SpeechandLanguageProcessing.DanielJurafsky&JamesH.Martin.Copyright\n",
      "c\n",
      "\n",
      "2015.All\n",
      "rightsreserved.DraftofJune26,2015.\n",
      "CHAPTER\n",
      "20\n",
      "InformationExtraction\n",
      "IamtheverymodelofamodernMajor-General,\n",
      "I'veinformationvegetable,animal,andmineral,\n",
      "IknowthekingsofEngland,andIquotethehistorical\n",
      "FromMarathontoWaterloo,inordercategorical...\n",
      "GilbertandSullivan,\n",
      "PiratesofPenzance\n",
      "Imaginethatyouareananalystwithaninvestmentthattracksairlinestocks.\n",
      "You'regiventhetaskofdeterminingtherelationship(ifany)betweenairlinean-\n",
      "nouncementsoffareincreasesandthebehavioroftheirstocksthenextday.His-\n",
      "toricaldataaboutstockpricesiseasytocomeby,butwhatabouttheairlinean-\n",
      "nouncements?Youwillneedtoknowatleastthenameoftheairline,thenatureof\n",
      "theproposedfarehike,thedatesoftheannouncement,andpossiblytheresponseof\n",
      "otherairlines.Fortunately,thesecanbeallfoundinnewsarticleslikethisone:\n",
      "Citinghighfuelprices,UnitedAirlinessaidFridayithasincreasedfares\n",
      "by$6perroundtripontosomecitiesalsoservedbylower-\n",
      "costcarriers.AmericanAirlines,aunitofAMRCo\n"
     ]
    }
   ],
   "source": [
    "inforExtractPDF = PyPDF2.PdfFileReader(infoExtractionBytes)\n",
    "print(inforExtractPDF.numPages)\n",
    "firstPage = inforExtractPDF.getPage(0)\n",
    "print(firstPage.extractText()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in progress\n",
    "\n",
    "## Word Docs\n",
    "\n",
    "Looks like `python-docx` may work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wenxi Xiao\n",
      "Professor Benjamin Soltoff\n",
      "MACS 30000\n",
      "10 October 2016\n",
      "Ethics of “Taste, Ties, and Time”\n",
      "\tIn 2008, sociologist Kevin Lewis and colleagues conduced a research project, entitled “Taste, Ties, and Time (3T),” to examine how race and cultural tastes could affect people’s social relationships. Researchers collected 1,640 college students’ Facebook profiles from Facebook.com and combined these data with the students’ school records, creating a new social network dataset. Through subsequent quantitative analyses of the dataset researchers concluded that gender, race, and socioeconomic status all influenced how these students behaved in social networks. In addition, the results showed that students’ Facebook friendships were correlated with their cultural preferences. Lewis and colleagues’ findings were published in the journal Social Networks and opened up a new branch in social science research. Despite its scientific potential, the project attracted critics from the public as well as the scientific community. The researchers were accused of violating research ethics, such that they scraped data without gaining informed consent and invading the students’ personal privacy by releasing the dataset to other researchers (Zimmer, 2010). Consequently, the students in the 3T project were identified, resulting a withdrawal of the dataset (Salganik, in open review). In this essay, I evaluate how the 3T project adheres to Salganik's four principles of ethical research, which are Respect for Persons, Beneficence, Justice, and Respect for Law and Public Interest.\n",
      "\tFirst of all, the 3T project violates the first principle, Respect for Persons, which is to ensure research participants’ autonomy (Salganik, in open review). According to the principle of Respect for Persons, people are entitled to be on their own free will to decide whether or not to participate in a given study. Additionally, special population such as children and prisoners are required to be treated with additional cautions. Researchers implement Respect for Persons by obtaining participants’ informed consent, a comprehensive written document allowing participants to be aware of the study’s procedures and potential risks. In the 3T project, researchers used students’ Facebook profiles data without the students’ awareness, not to mention obtaining informed consent. Such conduct clearly disobeyed the Respect for Persons principle. Although Lewis and colleagues claimed that when people registered for a Facebook account they agreed to allow Facebook to use their online data for research purposes by checking the term of use, it is still the researchers’ responsibility to explicitly give the students an opportunity to choose if they wanted their data to be included. After all, not many people carefully read all the items in term of use. Admittedly, violating the principle of Respect for Persons does not doom a study to a forbidden fate, but rather it alerts the researchers that their study needs amendments for being a more ethical one. \n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "r = requests.get('https://github.com/xiaow2/persp-analysis/raw/02772bc5baf4044ba6410170ca740f14cd6155d5/assignments/short%20paper%201.docx', stream=True)\n",
    "d = docx.Document(io.BytesIO(r.content))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR\n",
    "\n",
    "`pytesseract` works but requires tesseract binary"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
