{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Intro\n",
    "\n",
    "Intro stuff ...\n",
    "\n",
    "# Scraping\n",
    "\n",
    "Before we can start analyzing content we need to obtain it. Sometimes it will be provided to us before hand, but often we will need to download it. As a starting example we will attempt to download the MACS 3000 syllabus from github. The course page is located at [github.com/UC-MACSS/persp-analysis](https://github.com/UC-MACSS/persp-analysis) so lets start with that.\n",
    "\n",
    "We can do this by making an HTTP GET request to that url, a GET request is simply a request to the server to provide the contents given by some url. The other request we will be using in this class is called a POST request and requests the server to take some content we provide. While the Python standard library does have the ability do make GET requests we will be using the [_requests_](http://docs.python-requests.org/en/master/) package as it is _'the only Non-GMO HTTP library for Python'_, also it provides a nicer interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#requests.get('https://github.com/UC-MACSS/persp-analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Response [200]'` means the server responded with what we asked for. If you get another number (e.g. 404) it likely means there was some kind of error, these codes are called HTTP response codes and a list of them can be found [here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). The response object contains all the data the server sent including the website's contents and the HTTP header. We are interested in the contents which we can access with the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" class=\"\">\n",
      "  <head prefix=\"og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# object: http://ogp.me/ns/object# article: http://ogp.me/ns/article# profile: http://ogp.me/ns/profile#\">\n",
      "    <meta charset='utf-8'>\n",
      "    \n",
      "\n",
      "    <link crossorigin=\"anonymous\" href=\"https://assets-cdn.github.com/assets/frameworks-cb4ede7df6d8670c4051172e4d6bc6916b3c765fa15b4ee9b348f157fdb85114.css\" media=\"all\" rel=\"stylesheet\" />\n",
      "    <link crossorigin=\"anonymous\" href=\"https://assets-cdn.github.com/assets/github-171d3f0f3e5bd93fdd10a9f389e058c1f415ee10ec550302a2b73c5aaf70ce2e.css\" media=\"all\" rel=\"stylesheet\" />\n",
      "    \n",
      "    \n",
      "    <link crossorigin=\"anonymous\" href=\"https://assets-cdn.github.com/assets/site-b637b3b72afffd79585a758c94c7bd5bc8d451dd7ff634ca3a1b23221da39613.css\" media=\"all\" rel=\"stylesheet\" />\n",
      "    \n",
      "\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "    <meta http-equiv=\"Content-Language\" content=\"en\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width\">\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://github.com/UC-MACSS/persp-analysis')\n",
    "print(r.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bunch of nonsense, what it is, is the start of the HTML that makes up the website. This is a version of XML and is meant to be read by computers. Luckily we have a computer to parse it for us. To do the parsing we will use [_Beautiful Soup_](https://www.crummy.com/software/BeautifulSoup/) which is a better xml parser than the one in the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GitHub - UC-MACSS/persp-analysis: Course materials for MACS 30000 (Perspectives on Computational Analysis)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         \n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "print(soup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better but there's a bunch of random whitespace and we have way more than just the `README.md` file. This is because the text we requested is for the whole web page, not just for the syllabus."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
