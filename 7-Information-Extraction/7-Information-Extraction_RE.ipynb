{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 - Information Extraction\n",
    "\n",
    "\n",
    "This week, we move from arbitrary textual classification to the use of computation and linguistic models to parse precise claims from documents. Rather than focusing on simply the *ideas* in a corpus, here we focus on understanding and extracting its precise *claims*. This process involves a sequential pipeline of classifying and structuring tokens from text, each of which generates potentially useful data for the content analyst. Steps in this process, which we examine in this notebook, include: 1) tagging words by their part of speech (POS) to reveal the linguistic role they play in the sentence (e.g., Verb, Noun, Adjective, etc.); 2) tagging words as named entities (NER) such as places or organizations; 3) structuring or \"parsing\" sentences into nested phrases that are local to, describe or depend on one another; and 4) extracting informational claims from those phrases, like the Subject-Verb-Object (SVO) triples we extract here. While much of this can be done directly in the python package NLTK that we introduced in week 2, here we use NLTK bindings to the Stanford NLP group's open software, written in Java. Try typing a sentence into the online version [here](http://nlp.stanford.edu:8080/corenlp/) to get a sense of its potential. It is superior in performance to NLTK's implementations, but takes time to run, and so for these exercises we will parse and extract information for a very small text corpus. Of course, for final projects that draw on these tools, we encourage you to install the software on your own machines or shared servers at the university (RCC, SSRC) in order to perform these operations on much more text. \n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.parse import stanford\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw.tree import TreeView\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to run this once to download everything, you will also need [Java 1.8+](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) if you are using Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting downloads, this will take 5-10 minutes\n",
      "../stanford-NLP/parser already exists, skipping download\n",
      "../stanford-NLP/ner already exists, skipping download\n",
      "../stanford-NLP/postagger already exists, skipping download\n",
      "../stanford-NLP/core already exists, skipping download\n",
      "Done setting up the Stanford NLP collection\n"
     ]
    }
   ],
   "source": [
    "lucem_illud.setupStanfordNLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have stanford-NLP setup before importing, so we are doing the import here. IF you have stanford-NLP working you can import at the beginning like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT YET WOKING\n",
    "\n",
    "Open Information Extraction is a module packaged within the Stanford Core NLP package, but it is not yet supported by `nltk`. As a result, we will be defining our own function that runs the Stanford Core NLP java code right here. For other projects, it is often useful to use Java or other programs (in C, C++) within a python workflow, and this is an example. `openIE()` takes in a string or list of strings and then produces as output all the subject, verb, object (SVO) triples Stanford Corenlp can find, as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def openIE(target):\n",
    "    if isinstance(target, list):\n",
    "        target = '\\n'.join(target)\n",
    "    #setup the java targets\n",
    "    jarPath = os.path.join(stanfordDir, 'core', 'stanford-corenlp-3.8.0.jar')\n",
    "\n",
    "    cp = '{}:CoreNLP-to-HTML.xsl:slf4j-api.jar:slf4j-simple.jar'.format(jarPath)\n",
    "    with tempfile.NamedTemporaryFile(mode = 'w', delete = False) as f:\n",
    "        #Core nlp requires a files, so we will make a temp one to pass to it\n",
    "        #This file should be deleted by the OS soon after it has been used\n",
    "        f.write(target)\n",
    "        f.seek(0)\n",
    "        print(\"Starting OpenIE run\")\n",
    "        #If you know what these options do then you should mess with them on your own machine and not the shared server\n",
    "        sp = subprocess.run(['java', '-mx2g', '-cp', '\"*\"', 'edu.stanford.nlp.naturalli.OpenIE', '-threads', '1', f.name], stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "        #Live stderr is non-trivial so this is the best we can do\n",
    "        print(sp.stderr.decode('utf-8'))\n",
    "        retSting = sp.stdout.decode('utf-8')\n",
    "    #Making the DataFrame, again having to pass a fake file, yay POSIX I guess\n",
    "    with io.StringIO(retSting) as f:\n",
    "        df = pandas.read_csv(f, delimiter = '\\t', names =['certainty', 'subject', 'verb', 'object'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will illustrate these tools on some *very* short examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the elephant in my pajamas.\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.\n",
      "Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [word_tokenize(t) for t in text]\n",
    "print('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In POS tagging, we classify each word by its semantic role in a sentence. The Stanford POS tagger uses the [Penn Treebank tag set]('http://repository.upenn.edu/cgi/viewcontent.cgi?article=1603&context=cis_reports') to POS tag words from input sentences. As discussed in the second assignment, this is a relatively precise tagset, which allows more informative tags, and also more opportunities to err :-).\n",
    "\n",
    "|#. |Tag |Description |\n",
    "|---|----|------------|\n",
    "|1.\t|CC\t|Coordinating conjunction\n",
    "|2.\t|CD\t|Cardinal number\n",
    "|3.\t|DT\t|Determiner\n",
    "|4.\t|EX\t|Existential there\n",
    "|5.\t|FW\t|Foreign word\n",
    "|6.\t|IN\t|Preposition or subordinating conjunction\n",
    "|7.\t|JJ\t|Adjective\n",
    "|8.\t|JJR|\tAdjective, comparative\n",
    "|9.\t|JJS|\tAdjective, superlative\n",
    "|10.|\tLS\t|List item marker\n",
    "|11.|\tMD\t|Modal\n",
    "|12.|\tNN\t|Noun, singular or mass\n",
    "|13.|\tNNS\t|Noun, plural\n",
    "|14.|\tNNP\t|Proper noun, singular\n",
    "|15.|\tNNPS|\tProper noun, plural\n",
    "|16.|\tPDT\t|Predeterminer\n",
    "|17.|\tPOS\t|Possessive ending\n",
    "|18.|\tPRP\t|Personal pronoun\n",
    "|19.|\tPRP\\$|\tPossessive pronoun\n",
    "|20.|\tRB\t|Adverb\n",
    "|21.|\tRBR\t|Adverb, comparative\n",
    "|22.|\tRBS\t|Adverb, superlative\n",
    "|23.|\tRP\t|Particle\n",
    "|24.|\tSYM\t|Symbol\n",
    "|25.|\tTO\t|to\n",
    "|26.|\tUH\t|Interjection\n",
    "|27.|\tVB\t|Verb, base form\n",
    "|28.|\tVBD\t|Verb, past tense\n",
    "|29.|\tVBG\t|Verb, gerund or present participle\n",
    "|30.|\tVBN\t|Verb, past participle\n",
    "|31.|\tVBP\t|Verb, non-3rd person singular present\n",
    "|32.|\tVBZ\t|Verb, 3rd person singular present\n",
    "|33.|\tWDT\t|Wh-determiner\n",
    "|34.|\tWP\t|Wh-pronoun\n",
    "|35.|\tWP$\t|Possessive wh-pronoun\n",
    "|36.|\tWRB\t|Wh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'PRP'), ('saw', 'VBD'), ('the', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NNS'), ('.', '.')], [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')], [('While', 'IN'), ('in', 'IN'), ('France', 'NNP'), (',', ','), ('Christine', 'NNP'), ('Lagarde', 'NNP'), ('discussed', 'VBD'), ('short-term', 'JJ'), ('stimulus', 'NN'), ('efforts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Wall', 'NNP'), ('Street', 'NNP'), ('Journal', 'NNP'), ('.', '.')], [('Trayvon', 'NNP'), ('Benjamin', 'NNP'), ('Martin', 'NNP'), ('was', 'VBD'), ('an', 'DT'), ('African', 'NNP'), ('American', 'NNP'), ('from', 'IN'), ('Miami', 'NNP'), ('Gardens', 'NNP'), (',', ','), ('Florida', 'NNP'), (',', ','), ('who', 'WP'), (',', ','), ('at', 'IN'), ('17', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('was', 'VBD'), ('fatally', 'RB'), ('shot', 'VBN'), ('by', 'IN'), ('George', 'NNP'), ('Zimmerman', 'NNP'), (',', ','), ('a', 'DT'), ('neighborhood', 'NN'), ('watch', 'NN'), ('volunteer', 'NN'), (',', ','), ('in', 'IN'), ('Sanford', 'NNP'), (',', ','), ('Florida', 'NNP'), ('.', '.')], [('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "pos_sents = stanford.postTagger.tag_sents(tokenized_text)\n",
    "print(pos_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite good. Now we will try POS tagging with a somewhat larger corpus. We consider a few of the top posts from the reddit data we used last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redditDF = pandas.read_csv('../data/reddit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the 10 highest scoring posts and tokenizing the sentences. Once again, notice that we aren't going to do any kind of stemming this week (although *semantic* normalization may be performed where we translate synonyms into the same focal word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>over_18</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goldie-gold</td>\n",
       "      <td>False</td>\n",
       "      <td>12650</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>This just happened...  So, I had a laptop syst...</td>\n",
       "      <td>Engineer is doing drugs!! No. No they aren't.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[This, just, happened, ...], [So, ,, I, had, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheDroolinFool</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Another tale from the out of hours IT desk... ...</td>\n",
       "      <td>\"I need you to fix Google Bing immediately!\"</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Another, tale, from, the, out, of, hours, IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clickity_clickity</td>\n",
       "      <td>False</td>\n",
       "      <td>13404</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>[Part 1](http://www.reddit.com/r/talesfromtech...</td>\n",
       "      <td>Jack, the Worst End User, Part 4</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[[, Part, 1, ], (, http, :, //www.reddit.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECGaz</td>\n",
       "      <td>False</td>\n",
       "      <td>13724</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>&gt; $Me  - Hello, IT.   &gt; $Usr - Hi, I am still ...</td>\n",
       "      <td>Hi, I am still off sick but I am not.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[&gt;, $, Me, -, Hello, ,, IT, .], [&gt;, $, Usr, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guitarsdontdance</td>\n",
       "      <td>False</td>\n",
       "      <td>14089</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>So my story starts on what was a normal day ta...</td>\n",
       "      <td>\"Don't bother sending a tech, I'll be dead by ...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[So, my, story, starts, on, what, was, a, nor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  over_18  score                subreddit  \\\n",
       "4        goldie-gold    False  12650  Tales From Tech Support   \n",
       "3     TheDroolinFool    False  13152  Tales From Tech Support   \n",
       "2  Clickity_clickity    False  13404  Tales From Tech Support   \n",
       "1             SECGaz    False  13724  Tales From Tech Support   \n",
       "0   guitarsdontdance    False  14089  Tales From Tech Support   \n",
       "\n",
       "                                                text  \\\n",
       "4  This just happened...  So, I had a laptop syst...   \n",
       "3  Another tale from the out of hours IT desk... ...   \n",
       "2  [Part 1](http://www.reddit.com/r/talesfromtech...   \n",
       "1  > $Me  - Hello, IT.   > $Usr - Hi, I am still ...   \n",
       "0  So my story starts on what was a normal day ta...   \n",
       "\n",
       "                                               title  \\\n",
       "4      Engineer is doing drugs!! No. No they aren't.   \n",
       "3       \"I need you to fix Google Bing immediately!\"   \n",
       "2                   Jack, the Worst End User, Part 4   \n",
       "1              Hi, I am still off sick but I am not.   \n",
       "0  \"Don't bother sending a tech, I'll be dead by ...   \n",
       "\n",
       "                                                 url  \\\n",
       "4  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "3  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "2  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "1  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "0  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "\n",
       "                                           sentences  \n",
       "4  [[This, just, happened, ...], [So, ,, I, had, ...  \n",
       "3  [[Another, tale, from, the, out, of, hours, IT...  \n",
       "2  [[[, Part, 1, ], (, http, :, //www.reddit.com/...  \n",
       "1  [[>, $, Me, -, Hello, ,, IT, .], [>, $, Usr, -...  \n",
       "0  [[So, my, story, starts, on, what, was, a, nor...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores = redditDF.sort_values('score')[-10:]\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores.index = range(len(redditTopScores) - 1, -1,-1) #Reindex to make things nice in the future\n",
    "redditTopScores[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, JJ), (year, NN), (,, ,), (Help, NN), ...\n",
       "8    [[(First, JJ), (post, NN), (in, IN), (quite, R...\n",
       "7    [[([, NNP), (Original, NNP), (Post, NNP), (], ...\n",
       "6    [[(I, PRP), (witnessed, VBD), (this, DT), (ast...\n",
       "5    [[(I, PRP), (work, VBP), (Helpdesk, NNP), (for...\n",
       "4    [[(This, DT), (just, RB), (happened, VBN), (.....\n",
       "3    [[(Another, DT), (tale, NN), (from, IN), (the,...\n",
       "2    [[([, NNP), (Part, NNP), (1, CD), (], FW), ((,...\n",
       "1    [[(>, JJR), ($, $), (Me, PRP), (-, :), (Hello,...\n",
       "0    [[(So, RB), (my, PRP$), (story, NN), (starts, ...\n",
       "Name: POS_sents, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And count the number of `NN` (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('password', 21),\n",
       " ('(', 19),\n",
       " ('time', 14),\n",
       " (')', 14),\n",
       " ('lot', 12),\n",
       " ('computer', 12),\n",
       " ('life', 11),\n",
       " ('email', 11),\n",
       " ('**Genius**', 10),\n",
       " ('message', 9),\n",
       " ('**Me**', 9),\n",
       " ('system', 9),\n",
       " ('day', 9),\n",
       " ('call', 8),\n",
       " ('laptop', 8),\n",
       " ('office', 8),\n",
       " ('part', 8),\n",
       " ('today', 8),\n",
       " ('story', 8),\n",
       " ('user', 7)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the number of top verbs (`VB`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 18),\n",
       " ('have', 17),\n",
       " ('get', 14),\n",
       " ('do', 11),\n",
       " ('change', 9),\n",
       " ('make', 8),\n",
       " ('know', 7),\n",
       " ('say', 7),\n",
       " ('help', 6),\n",
       " ('look', 6),\n",
       " ('tell', 6),\n",
       " ('send', 6),\n",
       " ('go', 5),\n",
       " ('work', 4),\n",
       " ('use', 4),\n",
       " ('receive', 4),\n",
       " ('thank', 4),\n",
       " ('feel', 4),\n",
       " ('want', 4),\n",
       " ('call', 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the adjectives that modify the word, \"computer\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unrestricted', 'own'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'computer'\n",
    "NResults = set()\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating POS tagger\n",
    "\n",
    "We can check the POS tagger by running it on a manually tagged corpus and identifying a reasonable error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank = nltk.corpus.treebank\n",
    "treeBank.tagged_sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stanfordTags = stanford.postTagger.tag_sents(treeBank.sents()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Dutch  \tStanford: JJ\tTreebank: NNP\n",
      "Word: publishing  \tStanford: NN\tTreebank: VBG\n",
      "Word: used  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: later  \tStanford: RB\tTreebank: JJ\n",
      "Word: New  \tStanford: NNP\tTreebank: JJ\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: replaced  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: JJ\n",
      "Word: expected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: study  \tStanford: VBD\tTreebank: VBP\n",
      "Word: studied  \tStanford: VBD\tTreebank: VBN\n",
      "Word: industrialized  \tStanford: JJ\tTreebank: VBN\n",
      "Word: Lorillard  \tStanford: NNP\tTreebank: NN\n",
      "Word: found  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: rejected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: poured  \tStanford: VBN\tTreebank: VBD\n",
      "Word: in  \tStanford: IN\tTreebank: RP\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "The Precision is 96.547%\n"
     ]
    }
   ],
   "source": [
    "NumDiffs = 0\n",
    "for sentIndex in range(len(stanfordTags)):\n",
    "    for wordIndex in range(len(stanfordTags[sentIndex])):\n",
    "        if stanfordTags[sentIndex][wordIndex][1] != treeBank.tagged_sents()[sentIndex][wordIndex][1]:\n",
    "            if treeBank.tagged_sents()[sentIndex][wordIndex][1] != '-NONE-':\n",
    "                print(\"Word: {}  \\tStanford: {}\\tTreebank: {}\".format(stanfordTags[sentIndex][wordIndex][0], stanfordTags[sentIndex][wordIndex][1], treeBank.tagged_sents()[sentIndex][wordIndex][1]))\n",
    "                NumDiffs += 1\n",
    "total = sum([len(s) for s in stanfordTags])\n",
    "print(\"The Precision is {:.3f}%\".format((total-NumDiffs)/total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the stanford POS tagger is quite good. Nevertheless, for a 20 word sentence, we only have a 66% chance ($1-.96^{20}$) of tagging (and later parsing) it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Your turn*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform POS tagging on a meaningful (but modest) subset of a corpus associated with your final project. Examine the list of words associated with at least three different parts of speech. Consider conditional associations (e.g., adjectives associated with nouns or adverbs with verbs of interest). What do these distributions suggest about your corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named-Entity Recognition\n",
    "\n",
    "Named Entity Recognition (NER) is also a classification task, which identifies named objects. Included with Stanford NER are a 4 class model trained on the CoNLL 2003 eng.train, a 7 class model trained on the MUC 6 and MUC 7 training data sets, and a 3 class model trained on both data sets plus some additional data (including ACE 2002 and limited data in-house) on the intersection of those class sets. \n",
    "\n",
    "**3 class**:\tLocation, Person, Organization\n",
    "\n",
    "**4 class**:\tLocation, Person, Organization, Misc\n",
    "\n",
    "**7 class**:\tLocation, Person, Organization, Money, Percent, Date, Time\n",
    "\n",
    "These models each use distributional similarity features, which provide some performance gain at the cost of increasing their size and runtime. Also available are the same models missing those features.\n",
    "\n",
    "(We note that the training data for the 3 class model does not include any material from the CoNLL eng.testa or eng.testb data sets, nor any of the MUC 6 or 7 test or devtest datasets, nor Alan Ritter's Twitter NER data, so all of these would be valid tests of its performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we tag our first set of exemplary sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'O'), ('saw', 'O'), ('the', 'O'), ('elephant', 'O'), ('in', 'O'), ('my', 'O'), ('pajamas', 'O'), ('.', 'O')], [('The', 'O'), ('quick', 'O'), ('brown', 'O'), ('fox', 'O'), ('jumped', 'O'), ('over', 'O'), ('the', 'O'), ('lazy', 'O'), ('dog', 'O'), ('.', 'O')], [('While', 'O'), ('in', 'O'), ('France', 'LOCATION'), (',', 'O'), ('Christine', 'PERSON'), ('Lagarde', 'PERSON'), ('discussed', 'O'), ('short-term', 'O'), ('stimulus', 'O'), ('efforts', 'O'), ('in', 'O'), ('a', 'O'), ('recent', 'O'), ('interview', 'O'), ('with', 'O'), ('the', 'O'), ('Wall', 'ORGANIZATION'), ('Street', 'ORGANIZATION'), ('Journal', 'ORGANIZATION'), ('.', 'O')], [('Trayvon', 'PERSON'), ('Benjamin', 'PERSON'), ('Martin', 'PERSON'), ('was', 'O'), ('an', 'O'), ('African', 'O'), ('American', 'O'), ('from', 'O'), ('Miami', 'LOCATION'), ('Gardens', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), (',', 'O'), ('who', 'O'), (',', 'O'), ('at', 'O'), ('17', 'O'), ('years', 'O'), ('old', 'O'), (',', 'O'), ('was', 'O'), ('fatally', 'O'), ('shot', 'O'), ('by', 'O'), ('George', 'PERSON'), ('Zimmerman', 'PERSON'), (',', 'O'), ('a', 'O'), ('neighborhood', 'O'), ('watch', 'O'), ('volunteer', 'O'), (',', 'O'), ('in', 'O'), ('Sanford', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), ('.', 'O')], [('Buffalo', 'LOCATION'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O'), ('buffalo', 'O'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "classified_sents = stanford.nerTagger.tag_sents(tokenized_text)\n",
    "print(classified_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run NER over our entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redditTopScores['classified_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, O), (year, O), (,, O), (Help, O), (De...\n",
       "8    [[(First, O), (post, O), (in, O), (quite, O), ...\n",
       "7    [[([, O), (Original, O), (Post, O), (], O), ((...\n",
       "6    [[(I, O), (witnessed, O), (this, O), (astoundi...\n",
       "5    [[(I, O), (work, O), (Helpdesk, ORGANIZATION),...\n",
       "4    [[(This, O), (just, O), (happened, O), (..., O...\n",
       "3    [[(Another, O), (tale, O), (from, O), (the, O)...\n",
       "2    [[([, O), (Part, O), (1, O), (], O), ((, O), (...\n",
       "1    [[(>, O), ($, O), (Me, O), (-, O), (Hello, O),...\n",
       "0    [[(So, O), (my, O), (story, O), (starts, O), (...\n",
       "Name: classified_sents, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['classified_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most common entities (which are, of course, boring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 401),\n",
       " ('I', 245),\n",
       " ('the', 226),\n",
       " (',', 205),\n",
       " ('to', 197),\n",
       " ('a', 143),\n",
       " ('and', 135),\n",
       " ('>', 106),\n",
       " ('you', 102),\n",
       " ('of', 97)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if ent in entityCounts:\n",
    "                entityCounts[ent] += 1\n",
    "            else:\n",
    "                entityCounts[ent] = 1\n",
    "sortedEntities = sorted(entityCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedEntities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or those occurring only twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'Desk',\n",
       " 'busy',\n",
       " 'fix',\n",
       " 'received',\n",
       " 'couple',\n",
       " 'Windows',\n",
       " 'anymore',\n",
       " 'Sure',\n",
       " 'error',\n",
       " 'DVD',\n",
       " 'opened',\n",
       " 'There',\n",
       " 'upside',\n",
       " 'local',\n",
       " 'bane',\n",
       " 'existence',\n",
       " 'learn',\n",
       " 'sometimes',\n",
       " 'generic',\n",
       " 'Everyone',\n",
       " 'login',\n",
       " 'times',\n",
       " 'guy',\n",
       " 'asset',\n",
       " 'name',\n",
       " 'Computer',\n",
       " 'nothing',\n",
       " \"'P4ssword\",\n",
       " 'P',\n",
       " 'Everything',\n",
       " 'case',\n",
       " '*type',\n",
       " 'S',\n",
       " 'LOWERCASE',\n",
       " 'used',\n",
       " 'four',\n",
       " 'Original',\n",
       " 'cancer',\n",
       " 'month',\n",
       " 'live',\n",
       " 'brave',\n",
       " 'bitter',\n",
       " 'passed',\n",
       " 'ago',\n",
       " 'absolutely',\n",
       " 'ready',\n",
       " 'proud',\n",
       " 'above',\n",
       " 'completely',\n",
       " 'its',\n",
       " 'meant',\n",
       " 'both',\n",
       " 'sharing',\n",
       " 'making',\n",
       " '100',\n",
       " 'share',\n",
       " 'looking',\n",
       " 'ALL',\n",
       " 'whom',\n",
       " 'business',\n",
       " 'whose',\n",
       " 'stronger',\n",
       " 'bad',\n",
       " 'mess',\n",
       " 'turn',\n",
       " 'first',\n",
       " 'others',\n",
       " 'Here',\n",
       " 'suggested',\n",
       " 'videos',\n",
       " 'While',\n",
       " 'stand',\n",
       " 'certain',\n",
       " 'enjoy',\n",
       " 'well',\n",
       " 'drowned',\n",
       " 'soon',\n",
       " 'understand',\n",
       " 'risks',\n",
       " 'myself',\n",
       " 'point',\n",
       " 'future',\n",
       " 'avoid',\n",
       " 'thinking',\n",
       " 'information',\n",
       " 'insurance',\n",
       " 'site',\n",
       " 'step',\n",
       " 'guide',\n",
       " 'discover',\n",
       " 'order',\n",
       " '5',\n",
       " 'slightly',\n",
       " 'spent',\n",
       " 'moment',\n",
       " 'arms',\n",
       " 'idea',\n",
       " 'food',\n",
       " 'party',\n",
       " 'played',\n",
       " 'family',\n",
       " 'allowed',\n",
       " 'cry',\n",
       " 'pretty',\n",
       " 'nice',\n",
       " 'loved',\n",
       " 'mind',\n",
       " 'favor',\n",
       " 'watched',\n",
       " 'Things',\n",
       " '17',\n",
       " 'small',\n",
       " 'lived',\n",
       " 'living',\n",
       " 'themselves',\n",
       " 'potential',\n",
       " 'happiness',\n",
       " 'sound',\n",
       " 'situation',\n",
       " 'believe',\n",
       " 'mistakes',\n",
       " 'same',\n",
       " 'scenario',\n",
       " 'difference',\n",
       " 'glad',\n",
       " 'flaws',\n",
       " 'stupid',\n",
       " 'yourself',\n",
       " 'ok',\n",
       " 'In',\n",
       " 'comments',\n",
       " 'SO',\n",
       " 'random',\n",
       " 'request',\n",
       " 'Give',\n",
       " 'THIS',\n",
       " 'response',\n",
       " 'Thanks',\n",
       " 'tears',\n",
       " 'helped',\n",
       " 'reply',\n",
       " 'large',\n",
       " 'academic',\n",
       " 'organization',\n",
       " 'CEO',\n",
       " 'Of',\n",
       " 'course',\n",
       " 'mailboxes',\n",
       " 'Fail',\n",
       " '#',\n",
       " 'check',\n",
       " 'generate',\n",
       " '=',\n",
       " 'real',\n",
       " 'stopped',\n",
       " 'avalanche',\n",
       " 'died',\n",
       " 'systems',\n",
       " 'staff',\n",
       " 'brought',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'plugged',\n",
       " 'hear',\n",
       " 'occasionally',\n",
       " 'operate',\n",
       " 'drawer*',\n",
       " 'try',\n",
       " 'hit',\n",
       " '*I',\n",
       " 'echo',\n",
       " 'heard',\n",
       " 'seconds',\n",
       " 'nose',\n",
       " 'working',\n",
       " 'BING',\n",
       " 'THE',\n",
       " '*Note',\n",
       " 'yes',\n",
       " 'different',\n",
       " 'search',\n",
       " 'immediately',\n",
       " 'connection',\n",
       " 'Turns',\n",
       " 'shortcut',\n",
       " 'okay',\n",
       " 'computering',\n",
       " 'taking',\n",
       " 'Steve',\n",
       " 'XYZ',\n",
       " 'however',\n",
       " 'forwarded',\n",
       " 'using',\n",
       " 'meet',\n",
       " 'ran',\n",
       " 'mouse',\n",
       " 'closed',\n",
       " 'window',\n",
       " 'revealing',\n",
       " 'me*',\n",
       " 'shaking',\n",
       " 'lunch',\n",
       " 'yelled',\n",
       " 'needed',\n",
       " 'key',\n",
       " 'week',\n",
       " 'pointed',\n",
       " 'door',\n",
       " 'blinked',\n",
       " 'Then',\n",
       " 'command',\n",
       " 'three',\n",
       " 'web',\n",
       " 'pages',\n",
       " 'person',\n",
       " 'Whatever',\n",
       " 'um',\n",
       " 'wrong',\n",
       " 'mother',\n",
       " 'done',\n",
       " 'way',\n",
       " 'weeks',\n",
       " 'since',\n",
       " 'stuff',\n",
       " 'took',\n",
       " 'Wow',\n",
       " 'gildings',\n",
       " 'One',\n",
       " 'HR',\n",
       " 'select',\n",
       " '*Are',\n",
       " 'Ca',\n",
       " 'building',\n",
       " 'holiday',\n",
       " 'pay',\n",
       " 'gods',\n",
       " 'expire',\n",
       " '60',\n",
       " 'anyway',\n",
       " 'User',\n",
       " 'DeskMugPhonePencil1',\n",
       " 'Thursday',\n",
       " 'return',\n",
       " 'calls',\n",
       " 'often',\n",
       " 'issues',\n",
       " 'service',\n",
       " 'older',\n",
       " 'types',\n",
       " 'speak',\n",
       " 'box',\n",
       " 'properly',\n",
       " 'personally',\n",
       " 'ask',\n",
       " 'supervisor',\n",
       " 'earlier',\n",
       " 'visit',\n",
       " 'terrible',\n",
       " 'willing',\n",
       " 'nasty']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in sortedEntities if x[1] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also list the most common \"non-objects\". (We note that we're not graphing these because there are so few here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jack', 17),\n",
       " ('Google', 6),\n",
       " ('Smith', 5),\n",
       " ('Steve', 2),\n",
       " ('Citrix', 1),\n",
       " ('Nono', 1),\n",
       " ('Reddit', 1),\n",
       " ('Helpdesk', 1),\n",
       " ('UK', 1),\n",
       " ('CMD', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonObjCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind == 'O':\n",
    "                continue\n",
    "            elif ent in nonObjCounts:\n",
    "                nonObjCounts[ent] += 1\n",
    "            else:\n",
    "                nonObjCounts[ent] = 1\n",
    "sortedNonObj = sorted(nonObjCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedNonObj[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the Organizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Google', 6), ('Citrix', 1), ('Helpdesk', 1), ('CMD', 1), ('GOOGLE', 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrgCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != 'ORGANIZATION':\n",
    "                continue\n",
    "            elif ent in OrgCounts:\n",
    "                OrgCounts[ent] += 1\n",
    "            else:\n",
    "                OrgCounts[ent] = 1\n",
    "sortedOrgs = sorted(OrgCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedOrgs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These, of course, have much smaller counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Your turn*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform NER on a (modest) subset of your corpus of interest. List all of the different kinds of entities tagged? What does their distribution suggest about the focus of your corpus? For a subset of your corpus, tally at least one type of named entity and calculate the Precision, Recall and F-score for the NER classification just performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "Here we will introduce the Stanford Parser by feeding it tokenized text from our initial example sentences. The parser is a dependency parser, but this initial program outputs a simple, self-explanatory phrase-structure representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('NNP', ['Trayvon']), Tree('NNP', ['Benjamin']), Tree('NNP', ['Martin'])]), Tree('VP', [Tree('VBD', ['was']), Tree('NP', [Tree('NP', [Tree('DT', ['an']), Tree('NNP', ['African']), Tree('NNP', ['American'])]), Tree('PP', [Tree('IN', ['from']), Tree('NP', [Tree('NP', [Tree('NNP', ['Miami']), Tree('NNPS', ['Gardens'])]), Tree(',', [',']), Tree('NP', [Tree('NNP', ['Florida'])]), Tree(',', [',']), Tree('SBAR', [Tree('WHNP', [Tree('WP', ['who'])]), Tree('S', [Tree(',', [',']), Tree('PP', [Tree('IN', ['at']), Tree('ADJP', [Tree('NP', [Tree('CD', ['17']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])])]), Tree(',', [',']), Tree('VP', [Tree('VBD', ['was']), Tree('ADVP', [Tree('RB', ['fatally'])]), Tree('VP', [Tree('VBN', ['shot']), Tree('PP', [Tree('IN', ['by']), Tree('NP', [Tree('NP', [Tree('NNP', ['George']), Tree('NNP', ['Zimmerman'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['a']), Tree('NN', ['neighborhood']), Tree('NN', ['watch']), Tree('NN', ['volunteer'])]), Tree(',', [','])])]), Tree('PP', [Tree('IN', ['in']), Tree('NP', [Tree('NNP', ['Sanford']), Tree(',', [',']), Tree('NNP', ['Florida'])])])])])])])])])])]), Tree('.', ['.'])])])]\n"
     ]
    }
   ],
   "source": [
    "parses = list(stanford.parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "fourthSentParseTree = list(parses[3]) #iterators so be careful about re-running code, without re-running this block\n",
    "print(fourthSentParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are a common data structure and there are a large number of things to do with them. What we are intetered in is the relationship between different types of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treeRelation(parsetree, relationType, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retList = []\n",
    "        for subT in parsetree.subtrees():\n",
    "            if subT.label() == relationType:\n",
    "                if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                    retList.append([(subT.label(), ' '.join(subT.leaves()))])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def treeSubRelation(parsetree, relationTypeScope, relationTypeTarget, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retSet = set()\n",
    "        for subT in parsetree.subtrees():\n",
    "            if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                if subT.label() == relationTypeScope:\n",
    "                    for subsub in subT.subtrees():\n",
    "                        if subsub.label()==relationTypeTarget:\n",
    "                            retSet.add(' '.join(subsub.leaves()))\n",
    "    return retSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('NP',\n",
       "   'an African American from Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')],\n",
       " [('NP',\n",
       "   'Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeRelation(fourthSentParseTree, 'NP', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Florida occurs twice in two different nested noun phrases in the sentence. \n",
    "\n",
    "We can also find all of the verbs within the noun phrase defined by one or more target words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shot'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeSubRelation(fourthSentParseTree, 'NP', 'VBN', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want to to look at the whole tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                   ROOT                                                                                                                       \n",
      "                                                                                                                    |                                                                                                                          \n",
      "                                                                                                                    S                                                                                                                         \n",
      "            ________________________________________________________________________________________________________|_______________________________________________________________________________________________________________________   \n",
      "           |                       VP                                                                                                                                                                                                       | \n",
      "           |              _________|______________                                                                                                                                                                                          |  \n",
      "           |             |                        NP                                                                                                                                                                                        | \n",
      "           |             |          ______________|________________                                                                                                                                                                         |  \n",
      "           |             |         |                               PP                                                                                                                                                                       | \n",
      "           |             |         |               ________________|___________                                                                                                                                                             |  \n",
      "           |             |         |              |                            NP                                                                                                                                                           | \n",
      "           |             |         |              |           _________________|____________________________________                                                                                                                        |  \n",
      "           |             |         |              |          |           |     |     |                             SBAR                                                                                                                     | \n",
      "           |             |         |              |          |           |     |     |    __________________________|______________________________                                                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |                                                         S                                                                                        | \n",
      "           |             |         |              |          |           |     |     |   |     ____________________________________________________|_______________________                                                                 |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |                                                 VP                                                               | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |    _____________________________________________|_______                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |                                               VP                                                       | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |      _________________________________________|________________________________________                |  \n",
      "           |             |         |              |          |           |     |     |   |    |           PP             |   |     |     |                      PP                                                          |               | \n",
      "           |             |         |              |          |           |     |     |   |    |    _______|____          |   |     |     |     _________________|__________                                                 |               |  \n",
      "           |             |         |              |          |           |     |     |   |    |   |           ADJP       |   |     |     |    |                            NP                                               PP              | \n",
      "           |             |         |              |          |           |     |     |   |    |   |        ____|____     |   |     |     |    |           _________________|________________________________     ___________|___            |  \n",
      "           NP            |         NP             |          NP          |     NP    |  WHNP  |   |       NP        |    |   |    ADVP   |    |          NP            |           NP                       |   |               NP          | \n",
      "    _______|_______      |    _____|_______       |      ____|_____      |     |     |   |    |   |    ___|____     |    |   |     |     |    |     _____|______       |    _______|_________________       |   |      _________|_____      |  \n",
      "  NNP     NNP     NNP   VBD  DT   NNP     NNP     IN   NNP        NNPS   ,    NNP    ,   WP   ,   IN  CD      NNS   JJ   ,  VBD    RB   VBN   IN  NNP          NNP     ,   DT      NN        NN      NN     ,   IN   NNP        ,    NNP    . \n",
      "   |       |       |     |   |     |       |      |     |          |     |     |     |   |    |   |   |        |    |    |   |     |     |    |    |            |      |   |       |         |       |      |   |     |         |     |     |  \n",
      "Trayvon Benjamin Martin was  an African American from Miami     Gardens  ,  Florida  ,  who   ,   at  17     years old   ,  was fatally shot  by George     Zimmerman  ,   a  neighborhood watch volunteer  ,   in Sanford      ,  Florida  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourthSentParseTree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Or another sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ROOT                           \n",
      "                      |                              \n",
      "                      S                             \n",
      "       _______________|___________________________   \n",
      "      |                          VP               | \n",
      "      |                __________|___             |  \n",
      "      |               |              PP           | \n",
      "      |               |      ________|___         |  \n",
      "      NP              |     |            NP       | \n",
      "  ____|__________     |     |     _______|____    |  \n",
      " DT   JJ    JJ   NN  VBD    IN   DT      JJ   NN  . \n",
      " |    |     |    |    |     |    |       |    |   |  \n",
      "The quick brown fox jumped over the     lazy dog  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "list(parses[1])[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dependency parsing and graph representations\n",
    "\n",
    "Dependency parsing was developed to robustly capture linguistic dependencies from text. The complex tags associated with these parses are detailed [here]('http://universaldependencies.org/u/overview/syntax.html'). When parsing with the dependency parser, we will work directly from the untokenized text. Note that no *processing* takes place before parsing sentences--we do not remove so-called stop words or anything that plays a syntactic role in the sentence, although anaphora resolution and related normalization may be performed before or after parsing to enhance the value of information extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x13f8df8c8>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'quick'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'brown'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [2, 3],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'fox'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'nmod': [9],\n",
      "                                      'nsubj': [4]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 0,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'jumped'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'over'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'lazy'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [8],\n",
      "                                      'case': [6],\n",
      "                                      'det': [7]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nmod',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'dog'}})\n"
     ]
    }
   ],
   "source": [
    "depParses = list(stanford.depParser.raw_parse_sents(text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "secondSentDepParseTree = list(depParses[1])[0] #iterators so be careful about re-running code, without re-running this block\n",
    "print(secondSentDepParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a graph and we can convert it to a dot file and use that to visulize it. Try traversing the tree and extracting elements that are nearby one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"472pt\" height=\"308pt\"\n",
       " viewBox=\"0.00 0.00 472.00 308.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 304)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-304 468,-304 468,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (jumped)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254,-263.597C254,-251.746 254,-235.817 254,-222.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"257.5,-222.084 254,-212.084 250.5,-222.084 257.5,-222.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"265.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (fox)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M229.205,-175.803C210.197,-162.62 183.785,-144.302 162.992,-129.882\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164.964,-126.99 154.752,-124.167 160.975,-132.742 164.964,-126.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node7\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"321\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (dog)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M267.558,-175.597C277.248,-163.159 290.437,-146.23 301.288,-132.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.306,-134.124 307.69,-124.084 298.784,-129.822 304.306,-134.124\"/>\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"29\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (The)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (quick)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"198\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (brown)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.561,-87.5966C94.4032,-74.6899 73.5641,-56.9457 56.8783,-42.7379\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.9467,-39.9022 49.0638,-36.084 54.4085,-45.2319 58.9467,-39.9022\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.953,-87.5966C123.169,-75.6285 119.419,-59.5011 116.254,-45.8907\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.647,-45.0313 113.973,-36.084 112.829,-46.6169 119.647,-45.0313\"/>\n",
       "<text text-anchor=\"middle\" x=\"138\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M143.705,-87.9364C148.264,-82.2416 153.361,-75.8558 158,-70 164.708,-61.5322 172.009,-52.2434 178.517,-43.9401\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.299,-46.0638 184.708,-36.0322 175.787,-41.7487 181.299,-46.0638\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"283\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (over)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>9&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M313.31,-87.5966C307.97,-75.5112 300.756,-59.1844 294.705,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.792,-43.8163 290.549,-36.084 291.389,-46.6455 297.792,-43.8163\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.5\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"359\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (the)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.69,-87.5966C334.03,-75.5112 341.244,-59.1844 347.295,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"350.611,-46.6455 351.451,-36.084 344.208,-43.8163 350.611,-46.6455\"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"434\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (lazy)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.596,-87.8033C360.764,-74.7375 384.559,-56.6277 403.428,-42.2673\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"405.606,-45.0083 411.444,-36.1669 401.366,-39.438 405.606,-45.0083\"/>\n",
       "<text text-anchor=\"middle\" x=\"404\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x13fc339e8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondSentGraph = graphviz.Source(secondSentDepParseTree.to_dot())\n",
    "secondSentGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"974pt\" height=\"572pt\"\n",
       " viewBox=\"0.00 0.00 974.00 572.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 568)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-568 970,-568 970,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node2\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (American)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;7 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234,-527.597C234,-515.746 234,-499.817 234,-486.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"237.5,-486.084 234,-476.084 230.5,-486.084 237.5,-486.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"245.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"76\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (Martin)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192.973,-439.935C180.888,-434.55 167.757,-428.342 156,-422 140.153,-413.452 123.253,-402.906 109.089,-393.625\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.927,-390.645 100.657,-388.04 107.061,-396.48 110.927,-390.645\"/>\n",
       "<text text-anchor=\"middle\" x=\"171.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (was)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219.025,-439.597C208.222,-427.042 193.481,-409.91 181.433,-395.908\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.876,-393.381 174.7,-388.084 178.57,-397.947 183.876,-393.381\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">cop</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (an)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234,-439.597C234,-427.746 234,-411.817 234,-398.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"237.5,-398.084 234,-388.084 230.5,-398.084 237.5,-398.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"319\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (African)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.201,-439.597C263.726,-426.925 280.859,-409.589 294.769,-395.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.574,-397.657 302.115,-388.084 292.596,-392.736 297.574,-397.657\"/>\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node9\" class=\"node\"><title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">10 (Gardens)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;10 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.029,-446.545C301.576,-440.766 327.229,-432.587 349,-422 364.511,-414.457 380.367,-403.803 393.321,-394.182\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"395.541,-396.891 401.382,-388.051 391.303,-391.319 395.541,-396.891\"/>\n",
       "<text text-anchor=\"middle\" x=\"393\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"42\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (Trayvon)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (Benjamin)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.1196,-351.597C64.3416,-339.511 57.8869,-323.184 52.4732,-309.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"55.6857,-308.097 48.7541,-300.084 49.1759,-310.67 55.6857,-308.097\"/>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.03,-351.993C113.236,-346.894 120.445,-340.818 126,-334 131.779,-326.907 136.296,-318.067 139.693,-309.749\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.979,-310.952 143.174,-300.359 136.416,-308.519 142.979,-310.952\"/>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>10&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.651,-353.36C363.185,-347.976 348.659,-341.411 336,-334 322.78,-326.26 309.342,-315.992 298.215,-306.699\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.434,-303.991 290.558,-300.155 295.886,-309.312 300.434,-303.991\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"359\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (Miami)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M390.172,-351.817C383.343,-346.855 376.76,-340.886 372,-334 367.178,-327.024 364.143,-318.403 362.234,-310.246\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"365.656,-309.503 360.368,-300.322 358.777,-310.796 365.656,-309.503\"/>\n",
       "<text text-anchor=\"middle\" x=\"402\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node12\" class=\"node\"><title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"456\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">12 (Florida)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M428.88,-351.597C433.658,-339.511 440.113,-323.184 445.527,-309.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"448.824,-310.67 449.246,-300.084 442.314,-308.097 448.824,-310.67\"/>\n",
       "<text text-anchor=\"middle\" x=\"459.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">appos</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node13\" class=\"node\"><title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"550\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">23 (shot)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;23 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>10&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M451.517,-351.861C460.743,-346.325 470.889,-340.052 480,-334 493.23,-325.213 507.459,-314.995 519.61,-306.022\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"521.717,-308.818 527.654,-300.043 517.54,-303.2 521.717,-308.818\"/>\n",
       "<text text-anchor=\"middle\" x=\"525\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node14\" class=\"node\"><title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"342\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">14 (who)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>23&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M516.419,-266.987C513.263,-265.894 510.089,-264.876 507,-264 463.135,-251.556 447.547,-264.784 406,-246 391.52,-239.453 377.475,-228.892 366.25,-219.073\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"368.362,-216.262 358.609,-212.123 363.652,-221.441 368.362,-216.262\"/>\n",
       "<text text-anchor=\"middle\" x=\"433.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubjpass</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node18\" class=\"node\"><title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"424\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">19 (old)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;19 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>23&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M516.74,-264.345C506.633,-258.88 495.653,-252.525 486,-246 473.854,-237.79 461.222,-227.716 450.554,-218.697\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"452.685,-215.914 442.819,-212.053 448.124,-221.224 452.685,-215.914\"/>\n",
       "<text text-anchor=\"middle\" x=\"501.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">advcl</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node19\" class=\"node\"><title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"505\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">21 (was)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;21 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>23&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M538.552,-263.833C535.003,-258.243 531.189,-251.945 528,-246 523.821,-238.211 519.707,-229.516 516.14,-221.542\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"519.305,-220.044 512.092,-212.283 512.891,-222.848 519.305,-220.044\"/>\n",
       "<text text-anchor=\"middle\" x=\"550.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">auxpass</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node20\" class=\"node\"><title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"595\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">22 (fatally)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M562.079,-263.919C565.795,-258.334 569.757,-252.017 573,-246 577.163,-238.275 581.146,-229.598 584.552,-221.622\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"587.798,-222.929 588.392,-212.351 581.331,-220.25 587.798,-222.929\"/>\n",
       "<text text-anchor=\"middle\" x=\"604\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node21\" class=\"node\"><title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"709\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">26 (Zimmerman)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;26 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>23&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M583.316,-268.114C598.186,-261.98 615.755,-254.2 631,-246 646.429,-237.701 662.761,-227.299 676.471,-218.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"678.784,-220.716 685.066,-212.185 674.835,-214.936 678.784,-220.716\"/>\n",
       "<text text-anchor=\"middle\" x=\"674\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node22\" class=\"node\"><title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"833\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">36 (Florida)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;36 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>23&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M583.462,-273.994C612.833,-267.578 656.583,-257.371 694,-246 723.223,-237.119 755.263,-225.495 781.21,-215.588\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"782.761,-218.741 790.837,-211.884 780.248,-212.208 782.761,-218.741\"/>\n",
       "<text text-anchor=\"middle\" x=\"756\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node15\" class=\"node\"><title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">16 (at)</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node16\" class=\"node\"><title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"445\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">17 (17)</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node17\" class=\"node\"><title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"445\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">18 (years)</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;17 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>18&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M445,-87.5966C445,-75.7459 445,-59.8169 445,-46.2917\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"448.5,-46.084 445,-36.084 441.5,-46.084 448.5,-46.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"470\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">nummod</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;16 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>19&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M411.656,-175.597C402.834,-163.159 390.826,-146.23 380.946,-132.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"383.758,-130.216 375.118,-124.084 378.048,-134.265 383.758,-130.216\"/>\n",
       "<text text-anchor=\"middle\" x=\"411.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;18 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>19&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M428.25,-175.597C431.172,-163.629 435.11,-147.501 438.434,-133.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"441.856,-134.629 440.828,-124.084 435.056,-132.968 441.856,-134.629\"/>\n",
       "<text text-anchor=\"middle\" x=\"474.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod:npmod</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node23\" class=\"node\"><title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"542\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">24 (by)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;24 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>26&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M658.525,-175.891C645.089,-170.719 630.768,-164.633 618,-158 602.5,-149.948 586.299,-139.408 572.856,-130.001\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"574.632,-126.969 564.456,-124.021 570.573,-132.672 574.632,-126.969\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node24\" class=\"node\"><title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">25 (George)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;25 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>26&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M678.059,-175.915C670.561,-170.817 662.989,-164.761 657,-158 650.68,-150.865 645.446,-141.918 641.372,-133.519\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"644.562,-132.078 637.268,-124.393 638.177,-134.949 644.562,-132.078\"/>\n",
       "<text text-anchor=\"middle\" x=\"687\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node25\" class=\"node\"><title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"740\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">31 (volunteer)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;31 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>26&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M715.273,-175.597C719.587,-163.629 725.401,-147.501 730.307,-133.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"733.743,-134.678 733.842,-124.084 727.158,-132.305 733.743,-134.678\"/>\n",
       "<text text-anchor=\"middle\" x=\"743.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">appos</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node29\" class=\"node\"><title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"833\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">33 (in)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;33 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>36&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M833,-175.597C833,-163.746 833,-147.817 833,-134.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"836.5,-134.084 833,-124.084 829.5,-134.084 836.5,-134.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"845.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node30\" class=\"node\"><title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"922\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">34 (Sanford)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;34 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>36&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M851.01,-175.597C864.246,-162.807 882.397,-145.268 897.032,-131.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"899.561,-133.55 904.32,-124.084 894.697,-128.516 899.561,-133.55\"/>\n",
       "<text text-anchor=\"middle\" x=\"915\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\"><title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"634\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">28 (a)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;28 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>31&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M718.804,-87.8033C702.916,-74.9132 680.978,-57.1141 663.395,-42.8489\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"665.13,-39.7494 655.159,-36.1669 660.72,-45.1853 665.13,-39.7494\"/>\n",
       "<text text-anchor=\"middle\" x=\"706\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node27\" class=\"node\"><title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"740\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">29 (neighborhood)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M740,-87.5966C740,-75.7459 740,-59.8169 740,-46.2917\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"743.5,-46.084 740,-36.084 736.5,-46.084 743.5,-46.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"770\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node28\" class=\"node\"><title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"857\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">30 (watch)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M775.238,-87.9043C784.883,-82.6513 795.119,-76.5204 804,-70 814.615,-62.2067 825.278,-52.4162 834.229,-43.5022\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"836.804,-45.8749 841.305,-36.2838 831.805,-40.9745 836.804,-45.8749\"/>\n",
       "<text text-anchor=\"middle\" x=\"852\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x13fc3c198>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(list(depParses[3])[0].to_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also do a dependency parse on the reddit sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topPostDepParse = list(stanford.depParser.parse_sents(redditTopScores['sentences'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a few seconds, but now lets look at the parse tree from one of the processed sentences.\n",
    "\n",
    "The sentence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So anyway , I get a call from an older gentleman who 's quite bitter and mean right off the bat ( does n't like that I asked for his address / telephone number to verify the account , hates that he has to speak with a machine before reaching an agent , etc . ) .\n"
     ]
    }
   ],
   "source": [
    "targetSentence = 7\n",
    "print(' '.join(redditTopScores['sentences'][0][targetSentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which leads to a very rich dependancy tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"1111pt\" height=\"836pt\"\n",
       " viewBox=\"0.00 0.00 1111.00 836.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 832)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-832 1107,-832 1107,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-806.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-718.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (get)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197,-791.597C197,-779.746 197,-763.817 197,-750.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.5,-750.084 197,-740.084 193.5,-750.084 200.5,-750.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-762.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (So)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.655,-715.979C145.909,-710.834 111.166,-701.379 84,-686 71.5995,-678.98 59.5793,-668.884 49.7996,-659.524\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.0344,-656.81 42.4723,-652.248 47.1022,-661.778 52.0344,-656.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"107\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (anyway)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.92,-704.66C162.066,-699.252 153.786,-692.85 147,-686 139.595,-678.526 132.732,-669.304 127.081,-660.766\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.97,-658.787 121.658,-652.218 124.059,-662.537 129.97,-658.787\"/>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (I)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197,-703.597C197,-691.746 197,-675.817 197,-662.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.5,-662.084 197,-652.084 193.5,-662.084 200.5,-662.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\"><title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">7 (call)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214.916,-703.993C220.547,-698.411 226.679,-692.078 232,-686 238.975,-678.033 246.144,-668.956 252.403,-660.689\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"255.376,-662.558 258.549,-652.449 249.764,-658.373 255.376,-662.558\"/>\n",
       "<text text-anchor=\"middle\" x=\"257.5\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node7\" class=\"node\"><title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"623\" y=\"-630.3\" font-family=\"Times,serif\" font-size=\"14.00\">34 (number)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;34 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.296,-715.489C293.77,-701.464 478.258,-664.22 569.861,-645.728\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"570.65,-649.139 579.76,-643.729 569.265,-642.277 570.65,-649.139\"/>\n",
       "<text text-anchor=\"middle\" x=\"459.5\" y=\"-674.3\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\"><title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"175\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">6 (a)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.573,-615.597C237.296,-602.807 217.718,-585.268 201.932,-571.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"203.854,-568.15 194.071,-564.084 199.184,-573.363 203.854,-568.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node9\" class=\"node\"><title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">11 (gentleman)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-615.597C271,-603.746 271,-587.817 271,-574.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.5,-574.084 271,-564.084 267.5,-574.084 274.5,-574.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node25\" class=\"node\"><title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">25 (like)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;25 -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>34&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M612.882,-615.597C605.787,-603.394 596.178,-586.867 588.17,-573.093\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"590.985,-570.97 582.933,-564.084 584.933,-574.488 590.985,-570.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"613.5\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">dep</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node32\" class=\"node\"><title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"672\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">33 (telephone)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;33 -->\n",
       "<g id=\"edge31\" class=\"edge\"><title>34&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M632.916,-615.597C639.869,-603.394 649.285,-586.867 657.133,-573.093\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"660.357,-574.505 662.266,-564.084 654.275,-571.04 660.357,-574.505\"/>\n",
       "<text text-anchor=\"middle\" x=\"682\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">compound</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node33\" class=\"node\"><title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"793\" y=\"-542.3\" font-family=\"Times,serif\" font-size=\"14.00\">36 (verify)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;36 -->\n",
       "<g id=\"edge32\" class=\"edge\"><title>34&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M666.463,-618.935C682.385,-613.191 700.331,-606.008 716,-598 731.694,-589.979 748.107,-579.443 761.728,-570.031\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"764.073,-572.661 770.24,-564.046 760.047,-566.935 764.073,-572.661\"/>\n",
       "<text text-anchor=\"middle\" x=\"750.5\" y=\"-586.3\" font-family=\"Times,serif\" font-size=\"14.00\">acl</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\"><title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>11&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.487,-527.935C219.606,-522.502 206.639,-516.268 195,-510 178.987,-501.377 161.82,-490.903 147.353,-481.697\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"149.033,-478.616 138.728,-476.156 145.25,-484.506 149.033,-478.616\"/>\n",
       "<text text-anchor=\"middle\" x=\"207.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\"><title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">9 (an)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254.608,-527.597C242.673,-514.925 226.346,-497.589 213.091,-483.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"215.495,-480.964 206.091,-476.084 210.399,-485.763 215.495,-480.964\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node12\" class=\"node\"><title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">10 (older)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-527.597C271,-515.746 271,-499.817 271,-486.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.5,-486.084 271,-476.084 267.5,-486.084 274.5,-486.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">amod</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node13\" class=\"node\"><title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"362\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">15 (bitter)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.415,-527.597C302.948,-514.807 321.507,-497.268 336.471,-483.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"339.059,-485.496 343.923,-476.084 334.251,-480.409 339.059,-485.496\"/>\n",
       "<text text-anchor=\"middle\" x=\"348\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\"><title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">12 (who)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;12 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>15&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M325.685,-443.275C322.421,-442.134 319.158,-441.026 316,-440 287.897,-430.871 279.327,-433.239 252,-422 232.762,-414.088 212.429,-403.12 195.786,-393.382\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.333,-390.23 186.949,-388.126 193.754,-396.246 197.333,-390.23\"/>\n",
       "<text text-anchor=\"middle\" x=\"267.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\"><title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">13 (&#39;s)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;13 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>15&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M334.312,-439.962C325.49,-434.379 315.75,-428.052 307,-422 294.402,-413.286 280.84,-403.253 269.167,-394.404\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271.116,-391.489 261.042,-388.206 266.87,-397.054 271.116,-391.489\"/>\n",
       "<text text-anchor=\"middle\" x=\"317.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">cop</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\"><title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">14 (quite)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M348.852,-439.752C345.034,-434.263 341.071,-428.043 338,-422 334.171,-414.466 330.81,-405.927 328.061,-398.019\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"331.367,-396.869 324.916,-388.464 324.718,-399.057 331.367,-396.869\"/>\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"406\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">16 (and)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M373.507,-439.865C377.059,-434.276 380.859,-427.971 384,-422 388.085,-414.234 392.045,-405.545 395.454,-397.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"398.698,-398.884 399.309,-388.307 392.235,-396.194 398.698,-398.884\"/>\n",
       "<text text-anchor=\"middle\" x=\"398.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">cc</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"493\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">17 (mean)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M388.195,-439.803C408.365,-426.562 436.427,-408.14 458.438,-393.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"460.412,-396.581 466.85,-388.167 456.57,-390.729 460.412,-396.581\"/>\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"451\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">18 (right)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M472.934,-351.687C468.004,-346.475 463.223,-340.419 460,-334 456.353,-326.737 454.16,-318.245 452.848,-310.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"456.312,-309.792 451.583,-300.311 449.367,-310.672 456.312,-309.792\"/>\n",
       "<text text-anchor=\"middle\" x=\"483\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">advmod</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node20\" class=\"node\"><title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"534\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">21 (bat)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;21 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>17&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M501.297,-351.597C507.059,-339.511 514.842,-323.184 521.371,-309.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"524.711,-310.617 525.855,-300.084 518.392,-307.604 524.711,-310.617\"/>\n",
       "<text text-anchor=\"middle\" x=\"534\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node21\" class=\"node\"><title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"495\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">19 (off)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;19 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>21&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M526.108,-263.597C520.627,-251.511 513.223,-235.184 507.013,-221.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.065,-219.746 502.747,-212.084 503.69,-222.637 510.065,-219.746\"/>\n",
       "<text text-anchor=\"middle\" x=\"530.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node22\" class=\"node\"><title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">20 (the)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;20 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>21&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M541.892,-263.597C547.373,-251.511 554.777,-235.184 560.987,-221.491\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"564.31,-222.637 565.253,-212.084 557.935,-219.746 564.31,-222.637\"/>\n",
       "<text text-anchor=\"middle\" x=\"566\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node23\" class=\"node\"><title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"492\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">23 (does)</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node24\" class=\"node\"><title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">24 (n&#39;t)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;23 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>25&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M556.608,-527.597C544.673,-514.925 528.346,-497.589 515.091,-483.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"517.495,-480.964 508.091,-476.084 512.399,-485.763 517.495,-480.964\"/>\n",
       "<text text-anchor=\"middle\" x=\"550.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">aux</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>25&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M573,-527.597C573,-515.746 573,-499.817 573,-486.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"576.5,-486.084 573,-476.084 569.5,-486.084 576.5,-486.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"583.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">neg</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\"><title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"657\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">28 (asked)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;28 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>25&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M589.999,-527.597C602.376,-514.925 619.308,-497.589 633.054,-483.516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"635.83,-485.683 640.313,-476.084 630.822,-480.792 635.83,-485.683\"/>\n",
       "<text text-anchor=\"middle\" x=\"642\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\"><title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"580\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">26 (that)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;26 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>28&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M640.397,-439.694C635.104,-434.097 629.258,-427.829 624,-422 616.403,-413.577 608.245,-404.215 601.044,-395.835\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"603.641,-393.487 594.481,-388.164 598.322,-398.038 603.641,-393.487\"/>\n",
       "<text text-anchor=\"middle\" x=\"638.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\"><title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"657\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">27 (I)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;27 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>28&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M657,-439.597C657,-427.746 657,-411.817 657,-398.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"660.5,-398.084 657,-388.084 653.5,-398.084 660.5,-398.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"672.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node29\" class=\"node\"><title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"745\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">31 (address)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;31 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>28&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M674.808,-439.597C687.895,-426.807 705.842,-409.268 720.313,-395.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"722.813,-397.577 727.519,-388.084 717.921,-392.57 722.813,-397.577\"/>\n",
       "<text text-anchor=\"middle\" x=\"724\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\"><title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"693\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">29 (for)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M734.477,-351.597C727.028,-339.277 716.913,-322.549 708.537,-308.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"711.499,-306.83 703.33,-300.084 705.509,-310.452 711.499,-306.83\"/>\n",
       "<text text-anchor=\"middle\" x=\"735.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\"><title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"771\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">30 (his)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M750.261,-351.597C753.88,-339.629 758.755,-323.501 762.87,-309.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"766.291,-310.669 765.835,-300.084 759.591,-308.643 766.291,-310.669\"/>\n",
       "<text text-anchor=\"middle\" x=\"790.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node34\" class=\"node\"><title>35</title>\n",
       "<text text-anchor=\"middle\" x=\"793\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">35 (to)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;35 -->\n",
       "<g id=\"edge33\" class=\"edge\"><title>36&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M793,-527.597C793,-515.746 793,-499.817 793,-486.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"796.5,-486.084 793,-476.084 789.5,-486.084 796.5,-486.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"807.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 38 -->\n",
       "<g id=\"node35\" class=\"node\"><title>38</title>\n",
       "<text text-anchor=\"middle\" x=\"890\" y=\"-454.3\" font-family=\"Times,serif\" font-size=\"14.00\">38 (account)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;38 -->\n",
       "<g id=\"edge34\" class=\"edge\"><title>36&#45;&gt;38</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M812.629,-527.597C827.187,-514.69 847.201,-496.946 863.226,-482.738\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"865.57,-485.337 870.731,-476.084 860.926,-480.099 865.57,-485.337\"/>\n",
       "<text text-anchor=\"middle\" x=\"862.5\" y=\"-498.3\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node36\" class=\"node\"><title>37</title>\n",
       "<text text-anchor=\"middle\" x=\"836\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">37 (the)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;37 -->\n",
       "<g id=\"edge35\" class=\"edge\"><title>38&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M879.072,-439.597C871.336,-427.277 860.833,-410.549 852.135,-396.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"855.009,-394.692 846.727,-388.084 849.081,-398.414 855.009,-394.692\"/>\n",
       "<text text-anchor=\"middle\" x=\"876\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node37\" class=\"node\"><title>40</title>\n",
       "<text text-anchor=\"middle\" x=\"920\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">40 (hates)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;40 -->\n",
       "<g id=\"edge36\" class=\"edge\"><title>38&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M896.071,-439.597C900.246,-427.629 905.872,-411.501 910.62,-397.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"914.051,-398.679 914.04,-388.084 907.442,-396.373 914.051,-398.679\"/>\n",
       "<text text-anchor=\"middle\" x=\"919.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 54 -->\n",
       "<g id=\"node38\" class=\"node\"><title>54</title>\n",
       "<text text-anchor=\"middle\" x=\"1004\" y=\"-366.3\" font-family=\"Times,serif\" font-size=\"14.00\">54 (etc)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;54 -->\n",
       "<g id=\"edge37\" class=\"edge\"><title>38&#45;&gt;54</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M912.796,-439.803C930.115,-426.737 954.121,-408.628 973.157,-394.267\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"975.369,-396.983 981.244,-388.167 971.153,-391.395 975.369,-396.983\"/>\n",
       "<text text-anchor=\"middle\" x=\"969.5\" y=\"-410.3\" font-family=\"Times,serif\" font-size=\"14.00\">conj</text>\n",
       "</g>\n",
       "<!-- 43 -->\n",
       "<g id=\"node39\" class=\"node\"><title>43</title>\n",
       "<text text-anchor=\"middle\" x=\"857\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">43 (has)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;43 -->\n",
       "<g id=\"edge38\" class=\"edge\"><title>40&#45;&gt;43</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M907.251,-351.597C898.14,-339.159 885.738,-322.23 875.535,-308.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"878.248,-306.083 869.515,-300.084 872.601,-310.219 878.248,-306.083\"/>\n",
       "<text text-anchor=\"middle\" x=\"913\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">ccomp</text>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g id=\"node40\" class=\"node\"><title>50</title>\n",
       "<text text-anchor=\"middle\" x=\"971\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">50 (reaching)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;50 -->\n",
       "<g id=\"edge39\" class=\"edge\"><title>40&#45;&gt;50</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M930.321,-351.597C937.627,-339.277 947.547,-322.549 955.761,-308.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"958.778,-310.471 960.869,-300.084 952.758,-306.9 958.778,-310.471\"/>\n",
       "<text text-anchor=\"middle\" x=\"965.5\" y=\"-322.3\" font-family=\"Times,serif\" font-size=\"14.00\">advcl</text>\n",
       "</g>\n",
       "<!-- 41 -->\n",
       "<g id=\"node41\" class=\"node\"><title>41</title>\n",
       "<text text-anchor=\"middle\" x=\"713\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">41 (that)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;41 -->\n",
       "<g id=\"edge40\" class=\"edge\"><title>43&#45;&gt;41</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M825.829,-267.524C812.649,-261.453 797.3,-253.882 784,-246 769.997,-237.701 755.266,-227.405 742.874,-218.241\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"744.806,-215.315 734.706,-212.116 740.607,-220.916 744.806,-215.315\"/>\n",
       "<text text-anchor=\"middle\" x=\"798.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 42 -->\n",
       "<g id=\"node42\" class=\"node\"><title>42</title>\n",
       "<text text-anchor=\"middle\" x=\"792\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">42 (he)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;42 -->\n",
       "<g id=\"edge41\" class=\"edge\"><title>43&#45;&gt;42</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M842.879,-263.681C838.386,-258.082 833.434,-251.818 829,-246 822.701,-237.735 815.982,-228.58 810.022,-220.335\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"812.814,-218.224 804.135,-212.148 807.131,-222.31 812.814,-218.224\"/>\n",
       "<text text-anchor=\"middle\" x=\"844.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">nsubj</text>\n",
       "</g>\n",
       "<!-- 45 -->\n",
       "<g id=\"node43\" class=\"node\"><title>45</title>\n",
       "<text text-anchor=\"middle\" x=\"876\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">45 (speak)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;45 -->\n",
       "<g id=\"edge42\" class=\"edge\"><title>43&#45;&gt;45</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M860.845,-263.597C863.489,-251.629 867.052,-235.501 870.059,-221.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"873.486,-222.604 872.226,-212.084 866.651,-221.093 873.486,-222.604\"/>\n",
       "<text text-anchor=\"middle\" x=\"887.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">xcomp</text>\n",
       "</g>\n",
       "<!-- 49 -->\n",
       "<g id=\"node48\" class=\"node\"><title>49</title>\n",
       "<text text-anchor=\"middle\" x=\"971\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">49 (before)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;49 -->\n",
       "<g id=\"edge47\" class=\"edge\"><title>50&#45;&gt;49</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M971,-263.597C971,-251.746 971,-235.817 971,-222.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"974.5,-222.084 971,-212.084 967.5,-222.084 974.5,-222.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"985.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node49\" class=\"node\"><title>52</title>\n",
       "<text text-anchor=\"middle\" x=\"1066\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">52 (agent)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;52 -->\n",
       "<g id=\"edge48\" class=\"edge\"><title>50&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M990.225,-263.597C1004.35,-250.807 1023.73,-233.268 1039.35,-219.126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1042.06,-221.39 1047.13,-212.084 1037.37,-216.2 1042.06,-221.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"1039.5\" y=\"-234.3\" font-family=\"Times,serif\" font-size=\"14.00\">dobj</text>\n",
       "</g>\n",
       "<!-- 44 -->\n",
       "<g id=\"node44\" class=\"node\"><title>44</title>\n",
       "<text text-anchor=\"middle\" x=\"850\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">44 (to)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;44 -->\n",
       "<g id=\"edge43\" class=\"edge\"><title>45&#45;&gt;44</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M870.739,-175.597C867.12,-163.629 862.245,-147.501 858.13,-133.891\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"861.409,-132.643 855.165,-124.084 854.709,-134.669 861.409,-132.643\"/>\n",
       "<text text-anchor=\"middle\" x=\"879.5\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">mark</text>\n",
       "</g>\n",
       "<!-- 48 -->\n",
       "<g id=\"node45\" class=\"node\"><title>48</title>\n",
       "<text text-anchor=\"middle\" x=\"941\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">48 (machine)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;48 -->\n",
       "<g id=\"edge44\" class=\"edge\"><title>45&#45;&gt;48</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M889.154,-175.597C898.554,-163.159 911.35,-146.23 921.877,-132.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"924.85,-134.172 928.088,-124.084 919.266,-129.951 924.85,-134.172\"/>\n",
       "<text text-anchor=\"middle\" x=\"930\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">nmod</text>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node46\" class=\"node\"><title>46</title>\n",
       "<text text-anchor=\"middle\" x=\"901\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">46 (with)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;46 -->\n",
       "<g id=\"edge45\" class=\"edge\"><title>48&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M932.905,-87.5966C927.284,-75.5112 919.69,-59.1844 913.321,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"916.337,-43.6751 908.946,-36.084 909.99,-46.6273 916.337,-43.6751\"/>\n",
       "<text text-anchor=\"middle\" x=\"936.5\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- 47 -->\n",
       "<g id=\"node47\" class=\"node\"><title>47</title>\n",
       "<text text-anchor=\"middle\" x=\"980\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">47 (a)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;47 -->\n",
       "<g id=\"edge46\" class=\"edge\"><title>48&#45;&gt;47</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M948.892,-87.5966C954.373,-75.5112 961.777,-59.1844 967.987,-45.4911\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"971.31,-46.6368 972.253,-36.084 964.935,-43.7458 971.31,-46.6368\"/>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node50\" class=\"node\"><title>51</title>\n",
       "<text text-anchor=\"middle\" x=\"1066\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\">51 (an)</text>\n",
       "</g>\n",
       "<!-- 52&#45;&gt;51 -->\n",
       "<g id=\"edge49\" class=\"edge\"><title>52&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1066,-175.597C1066,-163.746 1066,-147.817 1066,-134.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1069.5,-134.084 1066,-124.084 1062.5,-134.084 1069.5,-134.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"1075\" y=\"-146.3\" font-family=\"Times,serif\" font-size=\"14.00\">det</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1126eb978>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(list(topPostDepParse[targetSentence])[0].to_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Your turn*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, parse a (modest) subset of your corpus of interest. How deep are the phrase structure and dependency parse trees nested? How does parse depth relate to perceived sentence complexity? What are five things you can extract from these parses for subsequent analysis? (e.g., nouns collocated in a noun phrase; adjectives that modify a noun; etc.) Capture these sets of things for a focal set of words (e.g., \"Bush\", \"Obama\", \"Trump\"). What do they reveal about the roles that these entities are perceive to play in the social world inscribed by your texts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction\n",
    "\n",
    "Information extraction approaches typically (as here, with Stanford's Open IE engine) ride atop the dependency parse of a sentence. They are a pre-coded example of the type analyzed in the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF = openIE(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`openIE()` prints everything stanford core produces and we can see from looking at it that initializing the dependency parser takes most of the time, so calling the function will always take at least 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No buffalos (because there were no verbs), but the rest is somewhat promising. Note, however, that it abandoned the key theme of the sentence about the tragic Trayvon Martin death (\"fatally shot\"), likely because it was buried so deeply within the complex phrase structure. This is obviously a challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Your thoughts*</span>\n",
    "\n",
    "<span style=\"color:red\">How would you extract relevant information about the Trayvon Martin sentence directly from the dependency parse (above)? Code an example here. (For instance, what compound nouns show up with what verb phrases within the sentence?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also look for subject, object, target triples in one of the reddit stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF = openIE(redditTopScores['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost 200 triples in only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(redditTopScores['sentences'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentences and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum([len(s) for s in redditTopScores['sentences'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find at the most common subject in this story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I is followed by various male pronouns and compound nouns (e.g., \"old man\"). 'I' occures most often with the following verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <span style=\"color:red\">*Your Turn*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform open information extraction on a modest subset of texts relevant to your final project. Analyze the relative attachment of several subjects relative to verbs and objects and visa versa? Describe how you would select among these statements to create a database of high-value statements for your project and do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
